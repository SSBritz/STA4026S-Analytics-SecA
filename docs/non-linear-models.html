<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Non-Linear Models | STA4026S – Honours Analytics Section A: Theory and Application of Supervised Learning</title>
  <meta name="description" content="STA4026S – Honours Analytics<br />
Section A: Theory and Application of Supervised Learning</p>" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Non-Linear Models | STA4026S – Honours Analytics Section A: Theory and Application of Supervised Learning" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Non-Linear Models | STA4026S – Honours Analytics Section A: Theory and Application of Supervised Learning" />
  
  
  

<meta name="author" content="Stefan S. Britz" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="classification-models.html"/>
<link rel="next" href="tree-based-methods.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.1/htmlwidgets.js"></script>
<script src="libs/rglWebGL-binding-1.0.1/rglWebGL.js"></script>
<link href="libs/rglwidgetClass-1.0.1/rgl.css" rel="stylesheet" />
<script src="libs/rglwidgetClass-1.0.1/rglClass.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/utils.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/buffer.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/subscenes.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/shaders.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/textures.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/projection.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/mouse.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/init.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/pieces.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/draw.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/controls.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/selection.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/rglTimer.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/pretty.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/axes.src.js"></script>
<script src="libs/rglwidgetClass-1.0.1/animation.src.js"></script>
<!--html_preserve--><script type = "text/plain" id = "rgl-vertex-shader">
#line 2 1
// File 1 is the vertex shader
#ifdef GL_ES
#ifdef GL_FRAGMENT_PRECISION_HIGH
precision highp float;
#else
precision mediump float;
#endif
#endif

attribute vec3 aPos;
attribute vec4 aCol;
uniform mat4 mvMatrix;
uniform mat4 prMatrix;
varying vec4 vCol;
varying vec4 vPosition;

#ifdef NEEDS_VNORMAL
attribute vec3 aNorm;
uniform mat4 normMatrix;
varying vec4 vNormal;
#endif

#if defined(HAS_TEXTURE) || defined (IS_TEXT)
attribute vec2 aTexcoord;
varying vec2 vTexcoord;
#endif

#ifdef FIXED_SIZE
uniform vec3 textScale;
#endif

#ifdef FIXED_QUADS
attribute vec3 aOfs;
#endif

#ifdef IS_TWOSIDED
#ifdef HAS_NORMALS
varying float normz;
uniform mat4 invPrMatrix;
#else
attribute vec3 aPos1;
attribute vec3 aPos2;
varying float normz;
#endif
#endif // IS_TWOSIDED

#ifdef FAT_LINES
attribute vec3 aNext;
attribute vec2 aPoint;
varying vec2 vPoint;
varying float vLength;
uniform float uAspect;
uniform float uLwd;
#endif


void main(void) {
  
#ifndef IS_BRUSH
#if defined(NCLIPPLANES) || !defined(FIXED_QUADS) || defined(HAS_FOG)
  vPosition = mvMatrix * vec4(aPos, 1.);
#endif
  
#ifndef FIXED_QUADS
  gl_Position = prMatrix * vPosition;
#endif
#endif // !IS_BRUSH
  
#ifdef IS_POINTS
  gl_PointSize = POINTSIZE;
#endif
  
  vCol = aCol;
  
#ifdef NEEDS_VNORMAL
  vNormal = normMatrix * vec4(-aNorm, dot(aNorm, aPos));
#endif
  
#ifdef IS_TWOSIDED
#ifdef HAS_NORMALS
  /* normz should be calculated *after* projection */
  normz = (invPrMatrix*vNormal).z;
#else
  vec4 pos1 = prMatrix*(mvMatrix*vec4(aPos1, 1.));
  pos1 = pos1/pos1.w - gl_Position/gl_Position.w;
  vec4 pos2 = prMatrix*(mvMatrix*vec4(aPos2, 1.));
  pos2 = pos2/pos2.w - gl_Position/gl_Position.w;
  normz = pos1.x*pos2.y - pos1.y*pos2.x;
#endif
#endif // IS_TWOSIDED
  
#ifdef NEEDS_VNORMAL
  vNormal = vec4(normalize(vNormal.xyz/vNormal.w), 1);
#endif
  
#if defined(HAS_TEXTURE) || defined(IS_TEXT)
  vTexcoord = aTexcoord;
#endif
  
#if defined(FIXED_SIZE) && !defined(ROTATING)
  vec4 pos = prMatrix * mvMatrix * vec4(aPos, 1.);
  pos = pos/pos.w;
  gl_Position = pos + vec4(aOfs*textScale, 0.);
#endif
  
#if defined(IS_SPRITES) && !defined(FIXED_SIZE)
  vec4 pos = mvMatrix * vec4(aPos, 1.);
  pos = pos/pos.w + vec4(aOfs,  0.);
  gl_Position = prMatrix*pos;
#endif
  
#ifdef FAT_LINES
  /* This code was inspired by Matt Deslauriers' code in 
   https://mattdesl.svbtle.com/drawing-lines-is-hard */
  vec2 aspectVec = vec2(uAspect, 1.0);
  mat4 projViewModel = prMatrix * mvMatrix;
  vec4 currentProjected = projViewModel * vec4(aPos, 1.0);
  currentProjected = currentProjected/currentProjected.w;
  vec4 nextProjected = projViewModel * vec4(aNext, 1.0);
  vec2 currentScreen = currentProjected.xy * aspectVec;
  vec2 nextScreen = (nextProjected.xy / nextProjected.w) * aspectVec;
  float len = uLwd;
  vec2 dir = vec2(1.0, 0.0);
  vPoint = aPoint;
  vLength = length(nextScreen - currentScreen)/2.0;
  vLength = vLength/(vLength + len);
  if (vLength > 0.0) {
    dir = normalize(nextScreen - currentScreen);
  }
  vec2 normal = vec2(-dir.y, dir.x);
  dir.x /= uAspect;
  normal.x /= uAspect;
  vec4 offset = vec4(len*(normal*aPoint.x*aPoint.y - dir), 0.0, 0.0);
  gl_Position = currentProjected + offset;
#endif
  
#ifdef IS_BRUSH
  gl_Position = vec4(aPos, 1.);
#endif
}
</script>
<script type = "text/plain" id = "rgl-fragment-shader">
#line 2 2
// File 2 is the fragment shader
#ifdef GL_ES
#ifdef GL_FRAGMENT_PRECISION_HIGH
precision highp float;
#else
precision mediump float;
#endif
#endif
varying vec4 vCol; // carries alpha
varying vec4 vPosition;
#if defined(HAS_TEXTURE) || defined (IS_TEXT)
varying vec2 vTexcoord;
uniform sampler2D uSampler;
#endif

#ifdef HAS_FOG
uniform int uFogMode;
uniform vec3 uFogColor;
uniform vec4 uFogParms;
#endif

#if defined(IS_LIT) && !defined(FIXED_QUADS)
varying vec4 vNormal;
#endif

#if NCLIPPLANES > 0
uniform vec4 vClipplane[NCLIPPLANES];
#endif

#if NLIGHTS > 0
uniform mat4 mvMatrix;
#endif

#ifdef IS_LIT
uniform vec3 emission;
uniform float shininess;
#if NLIGHTS > 0
uniform vec3 ambient[NLIGHTS];
uniform vec3 specular[NLIGHTS]; // light*material
uniform vec3 diffuse[NLIGHTS];
uniform vec3 lightDir[NLIGHTS];
uniform bool viewpoint[NLIGHTS];
uniform bool finite[NLIGHTS];
#endif
#endif // IS_LIT

#ifdef IS_TWOSIDED
uniform bool front;
varying float normz;
#endif

#ifdef FAT_LINES
varying vec2 vPoint;
varying float vLength;
#endif

void main(void) {
  vec4 fragColor;
#ifdef FAT_LINES
  vec2 point = vPoint;
  bool neg = point.y < 0.0;
  point.y = neg ? (point.y + vLength)/(1.0 - vLength) :
                 -(point.y - vLength)/(1.0 - vLength);
#if defined(IS_TRANSPARENT) && defined(IS_LINESTRIP)
  if (neg && length(point) <= 1.0) discard;
#endif
  point.y = min(point.y, 0.0);
  if (length(point) > 1.0) discard;
#endif // FAT_LINES
  
#ifdef ROUND_POINTS
  vec2 coord = gl_PointCoord - vec2(0.5);
  if (length(coord) > 0.5) discard;
#endif
  
#if NCLIPPLANES > 0
  for (int i = 0; i < NCLIPPLANES; i++)
    if (dot(vPosition, vClipplane[i]) < 0.0) discard;
#endif
    
#ifdef FIXED_QUADS
    vec3 n = vec3(0., 0., 1.);
#elif defined(IS_LIT)
    vec3 n = normalize(vNormal.xyz);
#endif
    
#ifdef IS_TWOSIDED
    if ((normz <= 0.) != front) discard;
#endif
    
#ifdef IS_LIT
    vec3 eye = normalize(-vPosition.xyz/vPosition.w);
    vec3 lightdir;
    vec4 colDiff;
    vec3 halfVec;
    vec4 lighteffect = vec4(emission, 0.);
    vec3 col;
    float nDotL;
#ifdef FIXED_QUADS
    n = -faceforward(n, n, eye);
#endif
    
#if NLIGHTS > 0
    for (int i=0;i<NLIGHTS;i++) {
      colDiff = vec4(vCol.rgb * diffuse[i], vCol.a);
      lightdir = lightDir[i];
      if (!viewpoint[i])
        lightdir = (mvMatrix * vec4(lightdir, 1.)).xyz;
      if (!finite[i]) {
        halfVec = normalize(lightdir + eye);
      } else {
        lightdir = normalize(lightdir - vPosition.xyz/vPosition.w);
        halfVec = normalize(lightdir + eye);
      }
      col = ambient[i];
      nDotL = dot(n, lightdir);
      col = col + max(nDotL, 0.) * colDiff.rgb;
      col = col + pow(max(dot(halfVec, n), 0.), shininess) * specular[i];
      lighteffect = lighteffect + vec4(col, colDiff.a);
    }
#endif
    
#else // not IS_LIT
    vec4 colDiff = vCol;
    vec4 lighteffect = colDiff;
#endif
    
#ifdef IS_TEXT
    vec4 textureColor = lighteffect*texture2D(uSampler, vTexcoord);
#endif
    
#ifdef HAS_TEXTURE
#ifdef TEXTURE_rgb
    vec4 textureColor = lighteffect*vec4(texture2D(uSampler, vTexcoord).rgb, 1.);
#endif
    
#ifdef TEXTURE_rgba
    vec4 textureColor = lighteffect*texture2D(uSampler, vTexcoord);
#endif
    
#ifdef TEXTURE_alpha
    vec4 textureColor = texture2D(uSampler, vTexcoord);
    float luminance = dot(vec3(1.,1.,1.), textureColor.rgb)/3.;
    textureColor =  vec4(lighteffect.rgb, lighteffect.a*luminance);
#endif
    
#ifdef TEXTURE_luminance
    vec4 textureColor = vec4(lighteffect.rgb*dot(texture2D(uSampler, vTexcoord).rgb, vec3(1.,1.,1.))/3., lighteffect.a);
#endif
    
#ifdef TEXTURE_luminance_alpha
    vec4 textureColor = texture2D(uSampler, vTexcoord);
    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;
    textureColor = vec4(lighteffect.rgb*luminance, lighteffect.a*textureColor.a);
#endif
    
    fragColor = textureColor;

#elif defined(IS_TEXT)
    if (textureColor.a < 0.1)
      discard;
    else
      fragColor = textureColor;
#else
    fragColor = lighteffect;
#endif // HAS_TEXTURE
    
#ifdef HAS_FOG
    // uFogParms elements: x = near, y = far, z = fogscale, w = (1-sin(FOV/2))/(1+sin(FOV/2))
    // In Exp and Exp2: use density = density/far
    // fogF will be the proportion of fog
    // Initialize it to the linear value
    float fogF;
    if (uFogMode > 0) {
      fogF = (uFogParms.y - vPosition.z/vPosition.w)/(uFogParms.y - uFogParms.x);
      if (uFogMode > 1)
        fogF = mix(uFogParms.w, 1.0, fogF);
      fogF = fogF*uFogParms.z;
      if (uFogMode == 2)
        fogF = 1.0 - exp(-fogF);
      // Docs are wrong: use (density*c)^2, not density*c^2
      // https://gitlab.freedesktop.org/mesa/mesa/-/blob/master/src/mesa/swrast/s_fog.c#L58
      else if (uFogMode == 3)
        fogF = 1.0 - exp(-fogF*fogF);
      fogF = clamp(fogF, 0.0, 1.0);
      gl_FragColor = vec4(mix(fragColor.rgb, uFogColor, fogF), fragColor.a);
    } else gl_FragColor = fragColor;
#else
    gl_FragColor = fragColor;
#endif // HAS_FOG
    
}
</script><!--/html_preserve-->
<script src="libs/CanvasMatrix4-1.0.1/CanvasMatrix.src.js"></script>
<script src="libs/plotly-binding-4.10.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.27/datatables.js"></script>
<link href="libs/dt-core-1.12.1/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.12.1/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.12.1/js/jquery.dataTables.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="figs/UCTLogo.jpg"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="supervised-learning.html"><a href="supervised-learning.html"><i class="fa fa-check"></i><b>2</b> Supervised Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="supervised-learning.html"><a href="supervised-learning.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>2.1</b> Bias-variance trade-off</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="supervised-learning.html"><a href="supervised-learning.html#example-1-simulation"><i class="fa fa-check"></i><b>2.1.1</b> Example 1 – Simulation</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="supervised-learning.html"><a href="supervised-learning.html#model-validation"><i class="fa fa-check"></i><b>2.2</b> Model validation</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="supervised-learning.html"><a href="supervised-learning.html#validation-set"><i class="fa fa-check"></i><b>2.2.1</b> Validation set</a></li>
<li class="chapter" data-level="2.2.2" data-path="supervised-learning.html"><a href="supervised-learning.html#k-fold-cv"><i class="fa fa-check"></i><b>2.2.2</b> <span class="math inline">\(k\)</span>-fold CV</a></li>
<li class="chapter" data-level="2.2.3" data-path="supervised-learning.html"><a href="supervised-learning.html#example-1-simulation-continued"><i class="fa fa-check"></i><b>2.2.3</b> Example 1 – Simulation (continued)</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="supervised-learning.html"><a href="supervised-learning.html#side-note-statistical-learning-vs-machine-learning"><i class="fa fa-check"></i><b>2.3</b> Side note: Statistical learning vs machine learning</a></li>
<li class="chapter" data-level="2.4" data-path="supervised-learning.html"><a href="supervised-learning.html#homework-exercises"><i class="fa fa-check"></i><b>2.4</b> Homework exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-model-selection-regularisation.html"><a href="linear-model-selection-regularisation.html"><i class="fa fa-check"></i><b>3</b> Linear Model Selection &amp; Regularisation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="linear-model-selection-regularisation.html"><a href="linear-model-selection-regularisation.html#linear-regression-models"><i class="fa fa-check"></i><b>3.1</b> Linear regression models</a></li>
<li class="chapter" data-level="3.2" data-path="linear-model-selection-regularisation.html"><a href="linear-model-selection-regularisation.html#l_1-and-l_2-regularisation"><i class="fa fa-check"></i><b>3.2</b> <span class="math inline">\(L_1\)</span> and <span class="math inline">\(L_2\)</span> regularisation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="linear-model-selection-regularisation.html"><a href="linear-model-selection-regularisation.html#ridge-regression-l_2"><i class="fa fa-check"></i><b>3.2.1</b> Ridge regression – <span class="math inline">\(L_2\)</span></a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-model-selection-regularisation.html"><a href="linear-model-selection-regularisation.html#example-2-prostate-cancer"><i class="fa fa-check"></i><b>3.2.2</b> Example 2 – Prostate cancer</a></li>
<li class="chapter" data-level="3.2.3" data-path="linear-model-selection-regularisation.html"><a href="linear-model-selection-regularisation.html#the-lasso-l_1"><i class="fa fa-check"></i><b>3.2.3</b> The Lasso – <span class="math inline">\(L_1\)</span></a></li>
<li class="chapter" data-level="3.2.4" data-path="linear-model-selection-regularisation.html"><a href="linear-model-selection-regularisation.html#example-2-prostate-cancer-continued"><i class="fa fa-check"></i><b>3.2.4</b> Example 2 – Prostate cancer (continued)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="linear-model-selection-regularisation.html"><a href="linear-model-selection-regularisation.html#elastic-net"><i class="fa fa-check"></i><b>3.3</b> Elastic-net</a></li>
<li class="chapter" data-level="3.4" data-path="linear-model-selection-regularisation.html"><a href="linear-model-selection-regularisation.html#homework-exercises-1"><i class="fa fa-check"></i><b>3.4</b> Homework exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="classification-models.html"><a href="classification-models.html"><i class="fa fa-check"></i><b>4</b> Classification Models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="classification-models.html"><a href="classification-models.html#logistic-regression"><i class="fa fa-check"></i><b>4.1</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="classification-models.html"><a href="classification-models.html#estimation"><i class="fa fa-check"></i><b>4.1.1</b> Estimation</a></li>
<li class="chapter" data-level="4.1.2" data-path="classification-models.html"><a href="classification-models.html#interpretation"><i class="fa fa-check"></i><b>4.1.2</b> Interpretation</a></li>
<li class="chapter" data-level="4.1.3" data-path="classification-models.html"><a href="classification-models.html#prediction"><i class="fa fa-check"></i><b>4.1.3</b> Prediction</a></li>
<li class="chapter" data-level="4.1.4" data-path="classification-models.html"><a href="classification-models.html#example-3-default-data"><i class="fa fa-check"></i><b>4.1.4</b> Example 3 – Default data</a></li>
<li class="chapter" data-level="4.1.5" data-path="classification-models.html"><a href="classification-models.html#decision-boundaries"><i class="fa fa-check"></i><b>4.1.5</b> Decision boundaries</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="classification-models.html"><a href="classification-models.html#model-evaluation"><i class="fa fa-check"></i><b>4.2</b> Model evaluation</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="classification-models.html"><a href="classification-models.html#changing-the-threshold"><i class="fa fa-check"></i><b>4.2.1</b> Changing the threshold</a></li>
<li class="chapter" data-level="4.2.2" data-path="classification-models.html"><a href="classification-models.html#roc-curve"><i class="fa fa-check"></i><b>4.2.2</b> ROC Curve</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="classification-models.html"><a href="classification-models.html#regularisation"><i class="fa fa-check"></i><b>4.3</b> Regularisation</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="classification-models.html"><a href="classification-models.html#example-4-heart-failure"><i class="fa fa-check"></i><b>4.3.1</b> Example 4 – Heart failure</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="classification-models.html"><a href="classification-models.html#homework-exercises-2"><i class="fa fa-check"></i><b>4.4</b> Homework exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>5</b> Non-Linear Models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="non-linear-models.html"><a href="non-linear-models.html#polynomial-regression"><i class="fa fa-check"></i><b>5.1</b> Polynomial regression</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="non-linear-models.html"><a href="non-linear-models.html#regression"><i class="fa fa-check"></i><b>5.1.1</b> Regression</a></li>
<li class="chapter" data-level="5.1.2" data-path="non-linear-models.html"><a href="non-linear-models.html#example-5-auto"><i class="fa fa-check"></i><b>5.1.2</b> Example 5 – Auto</a></li>
<li class="chapter" data-level="5.1.3" data-path="non-linear-models.html"><a href="non-linear-models.html#classification"><i class="fa fa-check"></i><b>5.1.3</b> Classification</a></li>
<li class="chapter" data-level="5.1.4" data-path="non-linear-models.html"><a href="non-linear-models.html#example-4-heart-failure-continued"><i class="fa fa-check"></i><b>5.1.4</b> Example 4 – Heart failure (continued)</a></li>
<li class="chapter" data-level="5.1.5" data-path="non-linear-models.html"><a href="non-linear-models.html#extension-to-basis-functions-and-generalised-additive-models"><i class="fa fa-check"></i><b>5.1.5</b> Extension to basis functions and generalised additive models</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="non-linear-models.html"><a href="non-linear-models.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>5.2</b> K-Nearest Neighbours</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="non-linear-models.html"><a href="non-linear-models.html#regression-1"><i class="fa fa-check"></i><b>5.2.1</b> Regression</a></li>
<li class="chapter" data-level="5.2.2" data-path="non-linear-models.html"><a href="non-linear-models.html#example-2-prostate-cancer-continued-1"><i class="fa fa-check"></i><b>5.2.2</b> Example 2 – Prostate cancer (continued)</a></li>
<li class="chapter" data-level="5.2.3" data-path="non-linear-models.html"><a href="non-linear-models.html#classification-1"><i class="fa fa-check"></i><b>5.2.3</b> Classification</a></li>
<li class="chapter" data-level="5.2.4" data-path="non-linear-models.html"><a href="non-linear-models.html#example-4-heart-failure-continued-1"><i class="fa fa-check"></i><b>5.2.4</b> Example 4 – Heart failure (continued)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="non-linear-models.html"><a href="non-linear-models.html#homework-exercises-3"><i class="fa fa-check"></i><b>5.3</b> Homework exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="tree-based-methods.html"><a href="tree-based-methods.html"><i class="fa fa-check"></i><b>6</b> Tree-based Methods</a>
<ul>
<li class="chapter" data-level="6.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#regression-trees"><i class="fa fa-check"></i><b>6.1</b> Regression trees</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#example-6-california-housing"><i class="fa fa-check"></i><b>6.1.1</b> Example 6 – California housing</a></li>
<li class="chapter" data-level="6.1.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#cost-complexity-pruning"><i class="fa fa-check"></i><b>6.1.2</b> Cost complexity pruning</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#classification-trees"><i class="fa fa-check"></i><b>6.2</b> Classification trees</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#splitting-criteria"><i class="fa fa-check"></i><b>6.2.1</b> Splitting criteria</a></li>
<li class="chapter" data-level="6.2.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#link-between-deviance-and-rss"><i class="fa fa-check"></i><b>6.2.2</b> Link between deviance and RSS</a></li>
<li class="chapter" data-level="6.2.3" data-path="tree-based-methods.html"><a href="tree-based-methods.html#cost-complexity-pruning-1"><i class="fa fa-check"></i><b>6.2.3</b> Cost complexity pruning</a></li>
<li class="chapter" data-level="6.2.4" data-path="tree-based-methods.html"><a href="tree-based-methods.html#example-7-titanic"><i class="fa fa-check"></i><b>6.2.4</b> Example 7 – Titanic</a></li>
<li class="chapter" data-level="6.2.5" data-path="tree-based-methods.html"><a href="tree-based-methods.html#example-8-iris"><i class="fa fa-check"></i><b>6.2.5</b> Example 8 – Iris</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="tree-based-methods.html"><a href="tree-based-methods.html#bagging-and-random-forests"><i class="fa fa-check"></i><b>6.3</b> Bagging and random forests</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#bagging"><i class="fa fa-check"></i><b>6.3.1</b> Bagging</a></li>
<li class="chapter" data-level="6.3.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#out-of-bag-error-estimation"><i class="fa fa-check"></i><b>6.3.2</b> Out-of-bag error estimation</a></li>
<li class="chapter" data-level="6.3.3" data-path="tree-based-methods.html"><a href="tree-based-methods.html#variable-importance"><i class="fa fa-check"></i><b>6.3.3</b> Variable importance</a></li>
<li class="chapter" data-level="6.3.4" data-path="tree-based-methods.html"><a href="tree-based-methods.html#random-forests"><i class="fa fa-check"></i><b>6.3.4</b> Random forests</a></li>
<li class="chapter" data-level="6.3.5" data-path="tree-based-methods.html"><a href="tree-based-methods.html#example-6-california-housing-continued"><i class="fa fa-check"></i><b>6.3.5</b> Example 6 – California housing (continued)</a></li>
<li class="chapter" data-level="6.3.6" data-path="tree-based-methods.html"><a href="tree-based-methods.html#example-8-titanic-continued"><i class="fa fa-check"></i><b>6.3.6</b> Example 8 – Titanic (continued)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="tree-based-methods.html"><a href="tree-based-methods.html#gradient-boosting"><i class="fa fa-check"></i><b>6.4</b> Gradient boosting</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#example-6-california-housing-continued-1"><i class="fa fa-check"></i><b>6.4.1</b> Example 6 – California housing (continued)</a></li>
<li class="chapter" data-level="6.4.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#partial-dependence-plots"><i class="fa fa-check"></i><b>6.4.2</b> Partial dependence plots</a></li>
<li class="chapter" data-level="6.4.3" data-path="tree-based-methods.html"><a href="tree-based-methods.html#xgboost"><i class="fa fa-check"></i><b>6.4.3</b> XGBoost</a></li>
<li class="chapter" data-level="6.4.4" data-path="tree-based-methods.html"><a href="tree-based-methods.html#example-7-titanic-continued"><i class="fa fa-check"></i><b>6.4.4</b> Example 7 – Titanic (continued)</a></li>
<li class="chapter" data-level="6.4.5" data-path="tree-based-methods.html"><a href="tree-based-methods.html#final-word"><i class="fa fa-check"></i><b>6.4.5</b> Final word</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="tree-based-methods.html"><a href="tree-based-methods.html#homework-exercises-4"><i class="fa fa-check"></i><b>6.5</b> Homework exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><p>STA4026S – Honours Analytics<br />
Section A: Theory and Application of Supervised Learning</p></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="non-linear-models" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Non-Linear Models<a href="non-linear-models.html#non-linear-models" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The regression and classification models we considered in the previous two chapters were predicated on the assumption – even after applying regularisation – that the input variables map linearly to the response. In reality, this will usually be an approximation at best, and wildly over simplistic at worst. Therefore, although these models offer clear interpretation and inference, this often comes at the cost of predictive power.</p>
<p>As we saw in chapter 2, we can increase a model’s flexibility in an attempt to decrease the bias component of the error, although we must again be cognizant of the fact the increased variance will eventually offset this gain. Some of the possible non-linear modelling approaches are <em>polynomial regression</em>, <em>step functions</em>, <em>regression and smoothing splines</em>, <em>multivariate adaptive regression splines (MARS)</em>, <em>local regression methods</em>, and <em>generalised additive models (GAMs)</em>. There are many more, and these are just the parametric techniques!</p>
<p>In this chapter we will only cover one parametric approach in polynomial regression and a simple non-parametric approach in K-nearest neighbours (KNN). Tree-based methods (including ensembling), another powerful non-parametric approach for both regression and classification, will be left for the final chapter. The reader is encouraged to explore some of the other aforementioned techniques in chapter 7 of <span class="citation">James et al. (2013)</span>.</p>
<div id="polynomial-regression" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Polynomial regression<a href="non-linear-models.html#polynomial-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Polynomial regression is simply a type of multiple regression in which the relationship between the independent variable(s) and the dependent variable is modelled as an <span class="math inline">\(d^{th}\)</span>-degree polynomial. In contrast to linear regression, where the relationship is modeled as a straight line/hyperplane, polynomial regression allows us to capture more complex, non-linear relationships between variables. Note that linear regression is the simplest case of polynomial regression, i.e. 1<sup>st</sup>-degree.</p>
<p>This approach can be applied to both regression (multiple linear regression) and classification problems (logistic regression).</p>
<div id="regression" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Regression<a href="non-linear-models.html#regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The polynomial regression model for a single predictor variable can be represented as follows:</p>
<span class="math display" id="eq:poly">\[\begin{equation}
Y = \beta_0 + \beta_1X + \beta_2X^2 + \beta_3X^3 + \cdots + \beta_dX^d + \epsilon.
\tag{5.1}
\end{equation}\]</span>
<p>By selecting an appropriate degree for the polynomial, we can capture different types of nonlinear relationships. As we have seen previously though, using a degree that is too high yields an overly complex model that will overfit on the training data. In practice it is unusual to use <span class="math inline">\(d &gt; 4\)</span>, since these highly flexible models can perform especially poorly near the boundaries of the observed predictors.</p>
<p>Let us illustrate the application via an example.</p>
</div>
<div id="example-5-auto" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Example 5 – Auto<a href="non-linear-models.html#example-5-auto" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We will consider the well-known <code>Auto</code> dataset, available in the <code>ISLR</code> package, which contains measurements on the mileage, engine specifications, and manufacturing information for 392 vehicles. A sensible relationship to model is how a vehicle’s mileage depends on its specifications.</p>
<p>First, visually explore the relationships between the numeric variables. One could do so quickly using the <code>pairs()</code> function, although the <code>ggplot</code> version offers more options for customisation.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="non-linear-models.html#cb52-1" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb52-2"><a href="non-linear-models.html#cb52-2" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb52-3"><a href="non-linear-models.html#cb52-3" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb52-4"><a href="non-linear-models.html#cb52-4" tabindex="-1"></a><span class="fu">data</span>(Auto)</span>
<span id="cb52-5"><a href="non-linear-models.html#cb52-5" tabindex="-1"></a></span>
<span id="cb52-6"><a href="non-linear-models.html#cb52-6" tabindex="-1"></a><span class="co">#Origin is categorical (as is name, but we will exclude this)</span></span>
<span id="cb52-7"><a href="non-linear-models.html#cb52-7" tabindex="-1"></a>Auto<span class="sc">$</span>origin <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(Auto<span class="sc">$</span>origin)</span>
<span id="cb52-8"><a href="non-linear-models.html#cb52-8" tabindex="-1"></a><span class="fu">levels</span>(Auto<span class="sc">$</span>origin) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;US&#39;</span>, <span class="st">&#39;Euro&#39;</span>, <span class="st">&#39;Japan&#39;</span>)</span>
<span id="cb52-9"><a href="non-linear-models.html#cb52-9" tabindex="-1"></a></span>
<span id="cb52-10"><a href="non-linear-models.html#cb52-10" tabindex="-1"></a>Auto <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(name, year)) <span class="sc">%&gt;%</span></span>
<span id="cb52-11"><a href="non-linear-models.html#cb52-11" tabindex="-1"></a>  <span class="fu">ggpairs</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">colour =</span> origin, <span class="at">alpha =</span> <span class="fl">0.5</span>), <span class="at">legend =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb52-12"><a href="non-linear-models.html#cb52-12" tabindex="-1"></a>  <span class="fu">scale_alpha_identity</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:auto-pairs"></span>
<img src="figs/auto-pairs-1.png" alt="Exploratory plot for the Auto dataset" width="864" />
<p class="caption">
Figure 5.1: Exploratory plot for the Auto dataset
</p>
</div>
<p>Since we are interested in the relationship between miles per gallon (<code>mpg</code>) and the other covariates, the focus is on the left-most column in Figure <a href="non-linear-models.html#fig:auto-pairs">5.1</a>. There are clear inverse relationships between mileage and displacement, horsepower, and weight, although neither of these seem to be linear, especially for American vehicles<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>. We do not require a highly flexible function to model these variables either; a quadratic polynomial will suffice.</p>
<p>For example, consider first the <code>horsepower</code> variable. Although this feature is highly significant in a linear model, the quadratic fit captures a higher proportion of the variation in the data. Here we use the <code>stargazer</code> package to print both models’ results for comparison.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="non-linear-models.html#cb53-1" tabindex="-1"></a><span class="fu">library</span>(stargazer) </span>
<span id="cb53-2"><a href="non-linear-models.html#cb53-2" tabindex="-1"></a></span>
<span id="cb53-3"><a href="non-linear-models.html#cb53-3" tabindex="-1"></a><span class="co"># Linear fit</span></span>
<span id="cb53-4"><a href="non-linear-models.html#cb53-4" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> horsepower, Auto)</span>
<span id="cb53-5"><a href="non-linear-models.html#cb53-5" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> <span class="fu">poly</span>(horsepower, <span class="dv">2</span>, <span class="at">raw =</span> T), <span class="at">data=</span>Auto)</span>
<span id="cb53-6"><a href="non-linear-models.html#cb53-6" tabindex="-1"></a><span class="co"># This is the same as lm(mpg ~ horsepower + I(horsepower^2), data=Auto)</span></span>
<span id="cb53-7"><a href="non-linear-models.html#cb53-7" tabindex="-1"></a><span class="co"># Using raw=F (the default) yields orthogonal polynomials</span></span>
<span id="cb53-8"><a href="non-linear-models.html#cb53-8" tabindex="-1"></a></span>
<span id="cb53-9"><a href="non-linear-models.html#cb53-9" tabindex="-1"></a><span class="fu">stargazer</span>(mod1, mod2, <span class="at">type =</span> <span class="st">&#39;html&#39;</span>, <span class="at">digits =</span> <span class="dv">3</span>, </span>
<span id="cb53-10"><a href="non-linear-models.html#cb53-10" tabindex="-1"></a>          <span class="at">star.cutoffs =</span> <span class="cn">NA</span>, <span class="at">report=</span>(<span class="st">&#39;vc*p&#39;</span>), <span class="at">omit.table.layout =</span> <span class="st">&#39;n&#39;</span>,</span>
<span id="cb53-11"><a href="non-linear-models.html#cb53-11" tabindex="-1"></a>          <span class="at">title =</span> <span class="st">&#39;Linear vs quadratic model results for the Auto dataset, using only horsepower&#39;</span>)</span></code></pre></div>
<table style="text-align:center">
<caption>
<strong>Linear vs quadratic model results for the Auto dataset, using only horsepower</strong>
</caption>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td colspan="2">
<em>Dependent variable:</em>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td colspan="2">
mpg
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(1)
</td>
<td>
(2)
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
horsepower
</td>
<td>
-0.158
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
p = 0.000
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
poly(horsepower, 2, raw = T)1
</td>
<td>
</td>
<td>
-0.466
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
p = 0.000
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
poly(horsepower, 2, raw = T)2
</td>
<td>
</td>
<td>
0.001
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
p = 0.000
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Constant
</td>
<td>
39.936
</td>
<td>
56.900
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
p = 0.000
</td>
<td>
p = 0.000
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
Observations
</td>
<td>
392
</td>
<td>
392
</td>
</tr>
<tr>
<td style="text-align:left">
R<sup>2</sup>
</td>
<td>
0.606
</td>
<td>
0.688
</td>
</tr>
<tr>
<td style="text-align:left">
Adjusted R<sup>2</sup>
</td>
<td>
0.605
</td>
<td>
0.686
</td>
</tr>
<tr>
<td style="text-align:left">
Residual Std. Error
</td>
<td>
4.906 (df = 390)
</td>
<td>
4.374 (df = 389)
</td>
</tr>
<tr>
<td style="text-align:left">
F Statistic
</td>
<td>
599.718 (df = 1; 390)
</td>
<td>
428.018 (df = 2; 389)
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
</table>
<p>In Figure <a href="non-linear-models.html#fig:auto-fits">5.2</a> we can clearly see that the quadratic fit (red line) captures the shape of the data better than the linear model (gray line), especially at the boundaries. However, note that we include the lower degree terms in the polynomial regression model as well – in this case the linear term alone – to capture these components in the data too.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="non-linear-models.html#cb54-1" tabindex="-1"></a><span class="co"># Plot mpg vs horsepower</span></span>
<span id="cb54-2"><a href="non-linear-models.html#cb54-2" tabindex="-1"></a><span class="fu">plot</span>(mpg <span class="sc">~</span> horsepower, <span class="at">data =</span> Auto, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">col=</span> <span class="st">&#39;darkblue&#39;</span>)</span>
<span id="cb54-3"><a href="non-linear-models.html#cb54-3" tabindex="-1"></a></span>
<span id="cb54-4"><a href="non-linear-models.html#cb54-4" tabindex="-1"></a><span class="co"># Add fits</span></span>
<span id="cb54-5"><a href="non-linear-models.html#cb54-5" tabindex="-1"></a>x_axs <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(Auto<span class="sc">$</span>horsepower), <span class="fu">max</span>(Auto<span class="sc">$</span>horsepower), <span class="at">length =</span> <span class="dv">100</span>)</span>
<span id="cb54-6"><a href="non-linear-models.html#cb54-6" tabindex="-1"></a><span class="fu">lines</span>(x_axs, <span class="fu">predict</span>(mod1, <span class="fu">data.frame</span>(<span class="at">horsepower =</span> x_axs)), <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb54-7"><a href="non-linear-models.html#cb54-7" tabindex="-1"></a><span class="fu">lines</span>(x_axs, <span class="fu">predict</span>(mod2, <span class="fu">data.frame</span>(<span class="at">horsepower =</span> x_axs)), <span class="at">col =</span> <span class="st">&#39;red&#39;</span>)</span>
<span id="cb54-8"><a href="non-linear-models.html#cb54-8" tabindex="-1"></a></span>
<span id="cb54-9"><a href="non-linear-models.html#cb54-9" tabindex="-1"></a><span class="co"># Calculate 95% confidence intervals around fits</span></span>
<span id="cb54-10"><a href="non-linear-models.html#cb54-10" tabindex="-1"></a>CI_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod1, <span class="fu">data.frame</span>(<span class="at">horsepower =</span> x_axs), </span>
<span id="cb54-11"><a href="non-linear-models.html#cb54-11" tabindex="-1"></a>                <span class="at">interval =</span> <span class="st">&#39;confidence&#39;</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb54-12"><a href="non-linear-models.html#cb54-12" tabindex="-1"></a>CI_2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod2, <span class="fu">data.frame</span>(<span class="at">horsepower =</span> x_axs), </span>
<span id="cb54-13"><a href="non-linear-models.html#cb54-13" tabindex="-1"></a>                <span class="at">interval =</span> <span class="st">&#39;confidence&#39;</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb54-14"><a href="non-linear-models.html#cb54-14" tabindex="-1"></a></span>
<span id="cb54-15"><a href="non-linear-models.html#cb54-15" tabindex="-1"></a><span class="co"># And add to plot</span></span>
<span id="cb54-16"><a href="non-linear-models.html#cb54-16" tabindex="-1"></a><span class="fu">matlines</span>(x_axs, CI_1[, <span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>], <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb54-17"><a href="non-linear-models.html#cb54-17" tabindex="-1"></a><span class="fu">matlines</span>(x_axs, CI_2[, <span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>], <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:auto-fits"></span>
<img src="figs/auto-fits-1.png" alt="Linear (gray) and quadratic (red) fits for the Auto dataset, using only horsepower. 95% confidence intervals are indicated with dashed lines." width="576" />
<p class="caption">
Figure 5.2: Linear (gray) and quadratic (red) fits for the Auto dataset, using only horsepower. 95% confidence intervals are indicated with dashed lines.
</p>
</div>
<p>One could now add the rest of the variables in the model, although the extreme collinearity will result in only some of them being included in the final model after applying variable selection/regularisation. This is left as an exercise.</p>
<p>Before moving on to a localised approach, we note that polynomial regression can also be applied to classification problems.</p>
</div>
<div id="classification" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Classification<a href="non-linear-models.html#classification" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the previous chapter we saw that the logistic regression model yielded linear decision boundaries since the logit is linear in <span class="math inline">\(\boldsymbol{X}\)</span>. To create non-linear decision boundaries, we simply add the polynomial terms to the logit in Equation 4.2:</p>
<span class="math display" id="eq:poly-log">\[\begin{equation}
\log \left( \frac{p(X)}{1 - p(X)} \right) = \beta_0 + \beta_1X + \beta_2X^2 + \beta_3X^3 + \cdots + \beta_dX^d,
\tag{5.2}
\end{equation}\]</span>
<p>for only a single predictor <span class="math inline">\(X\)</span>. More variables can be added to the model in a similar fashion.</p>
<p>We will once again illustrate this by means of an example, by returning to the heart failure dataset first seen in section 4.3.1.</p>
</div>
<div id="example-4-heart-failure-continued" class="section level3 hasAnchor" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Example 4 – Heart failure (continued)<a href="non-linear-models.html#example-4-heart-failure-continued" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For illustration purposes we will focus on two of the numeric predictors, namely <code>age</code> and <code>ejection_fraction</code>. Fitting a linear logistic regression model on the entire dataset using only these two variables yields the decision boundary displayed in <a href="non-linear-models.html#fig:lin-log">5.3</a>:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="non-linear-models.html#cb55-1" tabindex="-1"></a><span class="co"># Read in the data and turn the categorical features to factors</span></span>
<span id="cb55-2"><a href="non-linear-models.html#cb55-2" tabindex="-1"></a>heart <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&#39;data/heart.csv&#39;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>,</span>
<span id="cb55-3"><a href="non-linear-models.html#cb55-3" tabindex="-1"></a>                  <span class="at">colClasses =</span> <span class="fu">c</span>(<span class="at">anaemia=</span><span class="st">&#39;factor&#39;</span>,</span>
<span id="cb55-4"><a href="non-linear-models.html#cb55-4" tabindex="-1"></a>                                 <span class="at">diabetes =</span> <span class="st">&#39;factor&#39;</span>,</span>
<span id="cb55-5"><a href="non-linear-models.html#cb55-5" tabindex="-1"></a>                                 <span class="at">high_blood_pressure =</span> <span class="st">&#39;factor&#39;</span>,</span>
<span id="cb55-6"><a href="non-linear-models.html#cb55-6" tabindex="-1"></a>                                 <span class="at">sex =</span> <span class="st">&#39;factor&#39;</span>,</span>
<span id="cb55-7"><a href="non-linear-models.html#cb55-7" tabindex="-1"></a>                                 <span class="at">smoking =</span> <span class="st">&#39;factor&#39;</span>,</span>
<span id="cb55-8"><a href="non-linear-models.html#cb55-8" tabindex="-1"></a>                                 <span class="at">DEATH_EVENT =</span> <span class="st">&#39;factor&#39;</span>))</span>
<span id="cb55-9"><a href="non-linear-models.html#cb55-9" tabindex="-1"></a></span>
<span id="cb55-10"><a href="non-linear-models.html#cb55-10" tabindex="-1"></a><span class="co"># Fit logistic regression (linear)</span></span>
<span id="cb55-11"><a href="non-linear-models.html#cb55-11" tabindex="-1"></a>lin_log <span class="ot">&lt;-</span> <span class="fu">glm</span>(DEATH_EVENT <span class="sc">~</span> age <span class="sc">+</span> ejection_fraction, </span>
<span id="cb55-12"><a href="non-linear-models.html#cb55-12" tabindex="-1"></a>               <span class="at">data =</span> heart, <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb55-13"><a href="non-linear-models.html#cb55-13" tabindex="-1"></a></span>
<span id="cb55-14"><a href="non-linear-models.html#cb55-14" tabindex="-1"></a>cfs1 <span class="ot">&lt;-</span> <span class="fu">coef</span>(lin_log) <span class="co">#Extract coefficients</span></span>
<span id="cb55-15"><a href="non-linear-models.html#cb55-15" tabindex="-1"></a></span>
<span id="cb55-16"><a href="non-linear-models.html#cb55-16" tabindex="-1"></a><span class="co"># Plot Age vs Ejection fraction</span></span>
<span id="cb55-17"><a href="non-linear-models.html#cb55-17" tabindex="-1"></a><span class="fu">plot</span>(heart<span class="sc">$</span>age, heart<span class="sc">$</span>ejection_fraction,</span>
<span id="cb55-18"><a href="non-linear-models.html#cb55-18" tabindex="-1"></a>     <span class="at">col =</span> <span class="fu">ifelse</span>(heart<span class="sc">$</span>DEATH_EVENT <span class="sc">==</span> <span class="st">&#39;1&#39;</span>, <span class="st">&#39;darkorange&#39;</span>, <span class="st">&#39;lightblue&#39;</span>),</span>
<span id="cb55-19"><a href="non-linear-models.html#cb55-19" tabindex="-1"></a>     <span class="at">pch =</span> <span class="fu">ifelse</span>(heart<span class="sc">$</span>DEATH_EVENT <span class="sc">==</span> <span class="st">&#39;1&#39;</span>, <span class="dv">3</span>, <span class="dv">1</span>),</span>
<span id="cb55-20"><a href="non-linear-models.html#cb55-20" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Age&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;Ejection fraction&#39;</span>)</span>
<span id="cb55-21"><a href="non-linear-models.html#cb55-21" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, <span class="fu">c</span>(<span class="st">&#39;Death&#39;</span>, <span class="st">&#39;Survival&#39;</span>), </span>
<span id="cb55-22"><a href="non-linear-models.html#cb55-22" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;darkorange&#39;</span>, <span class="st">&#39;lightblue&#39;</span>), </span>
<span id="cb55-23"><a href="non-linear-models.html#cb55-23" tabindex="-1"></a>       <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb55-24"><a href="non-linear-models.html#cb55-24" tabindex="-1"></a></span>
<span id="cb55-25"><a href="non-linear-models.html#cb55-25" tabindex="-1"></a><span class="co"># Add the decision boundary</span></span>
<span id="cb55-26"><a href="non-linear-models.html#cb55-26" tabindex="-1"></a><span class="fu">abline</span>(<span class="sc">-</span>cfs1[<span class="dv">1</span>]<span class="sc">/</span>cfs1[<span class="dv">3</span>], <span class="sc">-</span>cfs1[<span class="dv">2</span>]<span class="sc">/</span>cfs1[<span class="dv">3</span>], <span class="at">col =</span> <span class="st">&#39;navy&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lin-log"></span>
<img src="figs/lin-log-1.png" alt="The linear logistic regression decision boundary for the heart failure dataset using age and ejection fraction as predictors." width="576" />
<p class="caption">
Figure 5.3: The linear logistic regression decision boundary for the heart failure dataset using age and ejection fraction as predictors.
</p>
</div>
<p>Let us now propose a more flexible model:</p>
<span class="math display">\[\begin{equation}
\log \left( \frac{p(\boldsymbol{X})}{1 - p(\boldsymbol{X})} \right) = \beta_0 + \beta_1\text{Age} + \beta_2\text{Age}^2 + \beta_3\text{Age}^3 + \beta_4\text{Age}^4 + \beta_5\text{EjectionFraction},
\end{equation}\]</span>
<p>The resulting non-linear decision boundary can be seen in Figure <a href="non-linear-models.html#fig:poly-log">5.4</a>.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="non-linear-models.html#cb56-1" tabindex="-1"></a><span class="co"># Fit logistic regression with 5th degree on age + serum_creatinine</span></span>
<span id="cb56-2"><a href="non-linear-models.html#cb56-2" tabindex="-1"></a>poly_log <span class="ot">&lt;-</span> <span class="fu">glm</span>(DEATH_EVENT <span class="sc">~</span> age <span class="sc">+</span> <span class="fu">I</span>(age<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(age<span class="sc">^</span><span class="dv">3</span>) <span class="sc">+</span> <span class="fu">I</span>(age<span class="sc">^</span><span class="dv">4</span>) <span class="sc">+</span> ejection_fraction, </span>
<span id="cb56-3"><a href="non-linear-models.html#cb56-3" tabindex="-1"></a>                <span class="at">data =</span> heart, <span class="at">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb56-4"><a href="non-linear-models.html#cb56-4" tabindex="-1"></a></span>
<span id="cb56-5"><a href="non-linear-models.html#cb56-5" tabindex="-1"></a>cfs4 <span class="ot">&lt;-</span> <span class="fu">coef</span>(poly_log) <span class="co">#Extract coefficients</span></span>
<span id="cb56-6"><a href="non-linear-models.html#cb56-6" tabindex="-1"></a></span>
<span id="cb56-7"><a href="non-linear-models.html#cb56-7" tabindex="-1"></a><span class="co"># Plot age vs ejection fraction</span></span>
<span id="cb56-8"><a href="non-linear-models.html#cb56-8" tabindex="-1"></a><span class="fu">plot</span>(heart<span class="sc">$</span>age, heart<span class="sc">$</span>ejection_fraction,</span>
<span id="cb56-9"><a href="non-linear-models.html#cb56-9" tabindex="-1"></a>     <span class="at">col =</span> <span class="fu">ifelse</span>(heart<span class="sc">$</span>DEATH_EVENT <span class="sc">==</span> <span class="st">&#39;1&#39;</span>, <span class="st">&#39;darkorange&#39;</span>, <span class="st">&#39;lightblue&#39;</span>),</span>
<span id="cb56-10"><a href="non-linear-models.html#cb56-10" tabindex="-1"></a>     <span class="at">pch =</span> <span class="fu">ifelse</span>(heart<span class="sc">$</span>DEATH_EVENT <span class="sc">==</span> <span class="st">&#39;1&#39;</span>, <span class="dv">3</span>, <span class="dv">1</span>),</span>
<span id="cb56-11"><a href="non-linear-models.html#cb56-11" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Age&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;Ejection fraction&#39;</span>)</span>
<span id="cb56-12"><a href="non-linear-models.html#cb56-12" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topright&#39;</span>, <span class="fu">c</span>(<span class="st">&#39;Death&#39;</span>, <span class="st">&#39;Survival&#39;</span>), </span>
<span id="cb56-13"><a href="non-linear-models.html#cb56-13" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;darkorange&#39;</span>, <span class="st">&#39;lightblue&#39;</span>), </span>
<span id="cb56-14"><a href="non-linear-models.html#cb56-14" tabindex="-1"></a>       <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">1</span>))</span>
<span id="cb56-15"><a href="non-linear-models.html#cb56-15" tabindex="-1"></a></span>
<span id="cb56-16"><a href="non-linear-models.html#cb56-16" tabindex="-1"></a><span class="co"># And add decision boundary</span></span>
<span id="cb56-17"><a href="non-linear-models.html#cb56-17" tabindex="-1"></a>xx <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(heart<span class="sc">$</span>age), <span class="fu">max</span>(heart<span class="sc">$</span>age), <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb56-18"><a href="non-linear-models.html#cb56-18" tabindex="-1"></a><span class="fu">lines</span>(xx, (<span class="fu">cbind</span>(<span class="dv">1</span>, xx, xx<span class="sc">^</span><span class="dv">2</span>, xx<span class="sc">^</span><span class="dv">3</span>, xx<span class="sc">^</span><span class="dv">4</span>) <span class="sc">%*%</span> cfs4[<span class="sc">-</span><span class="dv">6</span>])<span class="sc">/-</span>cfs4[<span class="dv">6</span>], <span class="co">#again, do the math!</span></span>
<span id="cb56-19"><a href="non-linear-models.html#cb56-19" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&#39;navy&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:poly-log"></span>
<img src="figs/poly-log-1.png" alt="The polynomial logistic regression decision boundary for the heart failure dataset using age^4^ and ejection fraction as predictors." width="576" />
<p class="caption">
Figure 5.4: The polynomial logistic regression decision boundary for the heart failure dataset using age<sup>4</sup> and ejection fraction as predictors.
</p>
</div>
<p>Of course we know that increased complexity does not necessarily imply improved fit or prediction. As with any other model, we would need to use out-of-sample data to determine whether this model better captures the underlying relationship in the data, whilst again considering what constitutes an ideal fit for the problem, i.e. weighing the asymmetric cost of misclassification. This is once again left as an exercise to the reader.</p>
<p>To limit the scope of this section of the course, we will end our discussion on non-linear parametric models here, with a brief addendum:</p>
</div>
<div id="extension-to-basis-functions-and-generalised-additive-models" class="section level3 hasAnchor" number="5.1.5">
<h3><span class="header-section-number">5.1.5</span> Extension to basis functions and generalised additive models<a href="non-linear-models.html#extension-to-basis-functions-and-generalised-additive-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Although polynomial regression is a valuable tool for capturing nonlinear relationships, it has its limitations, especially when dealing with complex data patterns. To address these limitations and provide more flexible modelling options, one can apply a more general <strong>basis function</strong> approach, where any family of functions or transformations are applied to the features.</p>
<p>These functions can also be fitted piecewise (locally), defining <strong>splines</strong>, which are generally smoothed to be piecewise continuous and linear at the boundaries.</p>
<p>Finally, Generalised Additive Models (GAMs) are a powerful extension of linear regression that allow for the modeling of complex interactions and nonlinear relationships without relying on a single global polynomial. They are particularly useful when dealing with high-dimensional data and when you want to capture intricate relationships between predictors and the target.</p>
<p>As with polynomial regression, these methods can be applied in both regression and classification contexts.</p>
</div>
</div>
<div id="k-nearest-neighbours" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> K-Nearest Neighbours<a href="non-linear-models.html#k-nearest-neighbours" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>K-Nearest Neighbours (KNN) is a simple non-parametric algorithm that can perform surprisingly well in various contexts. At its core, KNN makes predictions based on the similarity between data points. It operates on the premise that similar data points tend to belong to the same class (in classification) or have similar target values (in regression).</p>
<p>During the training phase, KNN stores the entire dataset in memory. No explicit model is constructed and no parameters are learned – the training phase simply involves memorising the data.</p>
<p>When making a prediction for a new, unseen data point, KNN looks at the <span class="math inline">\(K\)</span> nearest data points from the training dataset, where <span class="math inline">\(K\)</span> is a user-defined <strong>hyperparameter</strong>. <strong>Euclidean distance</strong> is generally employed as distance metric, although other measurements such as Manhattan distance and the Minkowski distance (of which the Euclidean distance is a special case) can also be used.</p>
<p>We will again consider these output separately for regression and classification tasks.</p>
<div id="regression-1" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Regression<a href="non-linear-models.html#regression-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider a continuous target variable. Given a value for <span class="math inline">\(K\)</span> and a prediction point <span class="math inline">\(\boldsymbol{x}_0\)</span>, KNN regression identifies the <span class="math inline">\(K\)</span> training observations that are closest to <span class="math inline">\(\boldsymbol{x}_0\)</span>, for now we will assume according to Euclidean distance. Denote these observations by <span class="math inline">\(\mathcal{N}_0\)</span>.</p>
<p>We then simply estimate <span class="math inline">\(f(\boldsymbol{x}_0)\)</span> as the average of the training responses in <span class="math inline">\(\mathcal{N}_0\)</span>. Therefore,</p>
<span class="math display" id="eq:knn-reg">\[\begin{equation}
\hat{f}(\boldsymbol{x}_0) = \frac{1}{K}\sum_{\boldsymbol{x}_i \in \mathcal{N}_0} y_i.
\tag{5.3}
\end{equation}\]</span>
<p>The choice of <span class="math inline">\(K\)</span> once again amounts to deciding on the flexibility of the decision boundary, as illustrated in the following example:</p>
</div>
<div id="example-2-prostate-cancer-continued-1" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Example 2 – Prostate cancer (continued)<a href="non-linear-models.html#example-2-prostate-cancer-continued-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider again the prostate cancer dataset from Chapter 3. We will focus on the variable that was least significant in the saturated model, namely <code>age</code>. Although the KNN algorithm is relatively simple to code from scratch, we will use the <code>knnreg()</code> function from the <code>caret</code> package.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="non-linear-models.html#cb57-1" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb57-2"><a href="non-linear-models.html#cb57-2" tabindex="-1"></a></span>
<span id="cb57-3"><a href="non-linear-models.html#cb57-3" tabindex="-1"></a>dat_pros <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&#39;data/prostate.csv&#39;</span>)</span>
<span id="cb57-4"><a href="non-linear-models.html#cb57-4" tabindex="-1"></a></span>
<span id="cb57-5"><a href="non-linear-models.html#cb57-5" tabindex="-1"></a><span class="co"># Extract train and test examples and drop the indicator column</span></span>
<span id="cb57-6"><a href="non-linear-models.html#cb57-6" tabindex="-1"></a>train_pros <span class="ot">&lt;-</span> dat_pros[dat_pros<span class="sc">$</span>train, <span class="sc">-</span><span class="dv">10</span>]</span>
<span id="cb57-7"><a href="non-linear-models.html#cb57-7" tabindex="-1"></a>test_pros <span class="ot">&lt;-</span> dat_pros[<span class="sc">!</span>dat_pros<span class="sc">$</span>train, <span class="sc">-</span><span class="dv">10</span>]</span>
<span id="cb57-8"><a href="non-linear-models.html#cb57-8" tabindex="-1"></a></span>
<span id="cb57-9"><a href="non-linear-models.html#cb57-9" tabindex="-1"></a><span class="co"># KNN reg with k = 3 and k = 10</span></span>
<span id="cb57-10"><a href="non-linear-models.html#cb57-10" tabindex="-1"></a>knn3 <span class="ot">&lt;-</span> <span class="fu">knnreg</span>(lpsa <span class="sc">~</span> age, train_pros, <span class="at">k =</span> <span class="dv">3</span>)</span>
<span id="cb57-11"><a href="non-linear-models.html#cb57-11" tabindex="-1"></a>knn10 <span class="ot">&lt;-</span> <span class="fu">knnreg</span>(lpsa <span class="sc">~</span> age, train_pros, <span class="at">k =</span> <span class="dv">10</span>)</span>
<span id="cb57-12"><a href="non-linear-models.html#cb57-12" tabindex="-1"></a></span>
<span id="cb57-13"><a href="non-linear-models.html#cb57-13" tabindex="-1"></a><span class="co"># Range of xs and predictions (fitted &quot;curve&quot;)</span></span>
<span id="cb57-14"><a href="non-linear-models.html#cb57-14" tabindex="-1"></a>xx <span class="ot">&lt;-</span> <span class="fu">min</span>(train_pros<span class="sc">$</span>age)<span class="sc">:</span><span class="fu">max</span>(train_pros<span class="sc">$</span>age) <span class="co">#Integer variable</span></span>
<span id="cb57-15"><a href="non-linear-models.html#cb57-15" tabindex="-1"></a>knn3_f <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn3, <span class="fu">data.frame</span>(<span class="at">age =</span> xx))</span>
<span id="cb57-16"><a href="non-linear-models.html#cb57-16" tabindex="-1"></a>knn10_f <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn10, <span class="fu">data.frame</span>(<span class="at">age =</span> xx))</span>
<span id="cb57-17"><a href="non-linear-models.html#cb57-17" tabindex="-1"></a></span>
<span id="cb57-18"><a href="non-linear-models.html#cb57-18" tabindex="-1"></a><span class="co"># Plots</span></span>
<span id="cb57-19"><a href="non-linear-models.html#cb57-19" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb57-20"><a href="non-linear-models.html#cb57-20" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(xx)){</span>
<span id="cb57-21"><a href="non-linear-models.html#cb57-21" tabindex="-1"></a>  <span class="co"># Need the distances just for illustration</span></span>
<span id="cb57-22"><a href="non-linear-models.html#cb57-22" tabindex="-1"></a>  f <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">c</span>(xx[i], train_pros<span class="sc">$</span>age), <span class="fu">c</span>(knn3_f[i], train_pros<span class="sc">$</span>lpsa))</span>
<span id="cb57-23"><a href="non-linear-models.html#cb57-23" tabindex="-1"></a>  dists <span class="ot">&lt;-</span> <span class="fu">dist</span>(f)[<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(train_pros)]</span>
<span id="cb57-24"><a href="non-linear-models.html#cb57-24" tabindex="-1"></a>  dist_ords <span class="ot">&lt;-</span> <span class="fu">order</span>(dists)</span>
<span id="cb57-25"><a href="non-linear-models.html#cb57-25" tabindex="-1"></a>  </span>
<span id="cb57-26"><a href="non-linear-models.html#cb57-26" tabindex="-1"></a>  <span class="co"># Left plot (k = 3)</span></span>
<span id="cb57-27"><a href="non-linear-models.html#cb57-27" tabindex="-1"></a>  <span class="fu">plot</span>(lpsa <span class="sc">~</span> age, train_pros, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">col =</span> <span class="st">&#39;navy&#39;</span>, <span class="at">main =</span> <span class="st">&#39;KNN regression with K = 3&#39;</span>)</span>
<span id="cb57-28"><a href="non-linear-models.html#cb57-28" tabindex="-1"></a>  <span class="fu">lines</span>(xx[<span class="dv">1</span><span class="sc">:</span>i], knn3_f[<span class="dv">1</span><span class="sc">:</span>i], <span class="at">type =</span> <span class="st">&#39;s&#39;</span>)</span>
<span id="cb57-29"><a href="non-linear-models.html#cb57-29" tabindex="-1"></a>  <span class="fu">segments</span>(<span class="fu">max</span>(xx)<span class="sc">*</span><span class="dv">2</span>, knn3_f[i], xx[i], knn3_f[i], <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb57-30"><a href="non-linear-models.html#cb57-30" tabindex="-1"></a>  <span class="fu">mtext</span>(<span class="fu">substitute</span>(<span class="fu">hat</span>(y) <span class="sc">==</span> a, </span>
<span id="cb57-31"><a href="non-linear-models.html#cb57-31" tabindex="-1"></a>                   <span class="fu">list</span>(<span class="at">a =</span> <span class="fu">round</span>(knn3_f[i], <span class="dv">1</span>))), </span>
<span id="cb57-32"><a href="non-linear-models.html#cb57-32" tabindex="-1"></a>        <span class="dv">4</span>, <span class="at">at =</span> knn3_f[i], <span class="at">padj =</span> <span class="fl">0.5</span>)</span>
<span id="cb57-33"><a href="non-linear-models.html#cb57-33" tabindex="-1"></a>  <span class="fu">segments</span>(train_pros<span class="sc">$</span>age[dist_ords[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]], train_pros<span class="sc">$</span>lpsa[dist_ords[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]],</span>
<span id="cb57-34"><a href="non-linear-models.html#cb57-34" tabindex="-1"></a>           xx[i], knn3_f[i], <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb57-35"><a href="non-linear-models.html#cb57-35" tabindex="-1"></a>  </span>
<span id="cb57-36"><a href="non-linear-models.html#cb57-36" tabindex="-1"></a>  <span class="co"># Right plot (k = 10)</span></span>
<span id="cb57-37"><a href="non-linear-models.html#cb57-37" tabindex="-1"></a>  <span class="fu">plot</span>(lpsa <span class="sc">~</span> age, train_pros, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">col =</span> <span class="st">&#39;navy&#39;</span>, <span class="at">main =</span> <span class="st">&#39;KNN regression with K = 10&#39;</span>)</span>
<span id="cb57-38"><a href="non-linear-models.html#cb57-38" tabindex="-1"></a>  <span class="fu">lines</span>(xx[<span class="dv">1</span><span class="sc">:</span>i], knn10_f[<span class="dv">1</span><span class="sc">:</span>i], <span class="at">type =</span> <span class="st">&#39;s&#39;</span>)</span>
<span id="cb57-39"><a href="non-linear-models.html#cb57-39" tabindex="-1"></a>  <span class="fu">segments</span>(<span class="fu">max</span>(xx)<span class="sc">*</span><span class="dv">2</span>, knn10_f[i], xx[i], knn10_f[i], <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb57-40"><a href="non-linear-models.html#cb57-40" tabindex="-1"></a>  <span class="fu">mtext</span>(<span class="fu">substitute</span>(<span class="fu">hat</span>(y) <span class="sc">==</span> a, </span>
<span id="cb57-41"><a href="non-linear-models.html#cb57-41" tabindex="-1"></a>                   <span class="fu">list</span>(<span class="at">a =</span> <span class="fu">round</span>(knn10_f[i], <span class="dv">1</span>))), </span>
<span id="cb57-42"><a href="non-linear-models.html#cb57-42" tabindex="-1"></a>        <span class="dv">4</span>, <span class="at">at =</span> knn10_f[i], <span class="at">padj =</span> <span class="fl">0.5</span>)</span>
<span id="cb57-43"><a href="non-linear-models.html#cb57-43" tabindex="-1"></a>  <span class="fu">segments</span>(train_pros<span class="sc">$</span>age[dist_ords[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]], train_pros<span class="sc">$</span>lpsa[dist_ords[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]],</span>
<span id="cb57-44"><a href="non-linear-models.html#cb57-44" tabindex="-1"></a>           xx[i], knn10_f[i], <span class="at">col =</span> <span class="st">&#39;darkgrey&#39;</span>)</span>
<span id="cb57-45"><a href="non-linear-models.html#cb57-45" tabindex="-1"></a>}</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:knn-reg1"></span>
<img src="figs/knn-reg1-.gif" alt="KNN regression with $K$ = 3 and $K$ = 10 on the prostate cancer dataset, using only age" width="864" />
<p class="caption">
Figure 5.5: KNN regression with <span class="math inline">\(K\)</span> = 3 and <span class="math inline">\(K\)</span> = 10 on the prostate cancer dataset, using only age
</p>
</div>
<p>As we can see in Figure <a href="non-linear-models.html#fig:knn-reg1">5.5</a>, there is more volatility in the fit for smaller values of <span class="math inline">\(K\)</span>. To further illustrate this, Figure <a href="non-linear-models.html#fig:knn-reg2">5.6</a> shows the different fits as <span class="math inline">\(K\)</span> changes.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="non-linear-models.html#cb58-1" tabindex="-1"></a><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>){</span>
<span id="cb58-2"><a href="non-linear-models.html#cb58-2" tabindex="-1"></a>  knn_fit <span class="ot">&lt;-</span> <span class="fu">knnreg</span>(lpsa <span class="sc">~</span> age, train_pros, <span class="at">k =</span> k)</span>
<span id="cb58-3"><a href="non-linear-models.html#cb58-3" tabindex="-1"></a>  knn_f <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_fit, <span class="fu">data.frame</span>(<span class="at">age =</span> xx))</span>
<span id="cb58-4"><a href="non-linear-models.html#cb58-4" tabindex="-1"></a>  <span class="fu">plot</span>(lpsa <span class="sc">~</span> age, train_pros, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">col =</span> <span class="st">&#39;navy&#39;</span>, <span class="at">main =</span> <span class="fu">paste0</span>(<span class="st">&#39;KNN regression with k = &#39;</span>, k))</span>
<span id="cb58-5"><a href="non-linear-models.html#cb58-5" tabindex="-1"></a>  <span class="fu">lines</span>(xx, knn_f, <span class="at">type =</span> <span class="st">&#39;s&#39;</span>)</span>
<span id="cb58-6"><a href="non-linear-models.html#cb58-6" tabindex="-1"></a>}</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:knn-reg2"></span>
<img src="figs/knn-reg2-.gif" alt="KNN regression on the prostate cancer dataset, using only age, for varying values of $K$" width="672" />
<p class="caption">
Figure 5.6: KNN regression on the prostate cancer dataset, using only age, for varying values of <span class="math inline">\(K\)</span>
</p>
</div>
<p>The resulting fit is a stepped function, which becomes a stepped surface when increasing the dimensionality, as can be seen in Figure <a href="non-linear-models.html#fig:knn-reg-2d">5.7</a> when adding <code>lbph</code> to the model and fitting a KNN regression with <span class="math inline">\(K = 3\)</span>.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="non-linear-models.html#cb59-1" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb59-2"><a href="non-linear-models.html#cb59-2" tabindex="-1"></a></span>
<span id="cb59-3"><a href="non-linear-models.html#cb59-3" tabindex="-1"></a><span class="co"># Fit</span></span>
<span id="cb59-4"><a href="non-linear-models.html#cb59-4" tabindex="-1"></a>knn3_2d <span class="ot">&lt;-</span> <span class="fu">knnreg</span>(lpsa <span class="sc">~</span> age <span class="sc">+</span> lbph, train_pros, <span class="at">k =</span> <span class="dv">3</span>)</span>
<span id="cb59-5"><a href="non-linear-models.html#cb59-5" tabindex="-1"></a></span>
<span id="cb59-6"><a href="non-linear-models.html#cb59-6" tabindex="-1"></a><span class="co"># Surface</span></span>
<span id="cb59-7"><a href="non-linear-models.html#cb59-7" tabindex="-1"></a>xx1 <span class="ot">&lt;-</span> <span class="fu">min</span>(train_pros<span class="sc">$</span>age)<span class="sc">:</span><span class="fu">max</span>(train_pros<span class="sc">$</span>age)</span>
<span id="cb59-8"><a href="non-linear-models.html#cb59-8" tabindex="-1"></a>xx2 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(train_pros<span class="sc">$</span>lbph), <span class="fu">max</span>(train_pros<span class="sc">$</span>lbph), <span class="at">length.out =</span> <span class="fu">length</span>(xx1))</span>
<span id="cb59-9"><a href="non-linear-models.html#cb59-9" tabindex="-1"></a>fgrid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">age =</span> xx1, <span class="at">lbph =</span> xx2)</span>
<span id="cb59-10"><a href="non-linear-models.html#cb59-10" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn3_2d, fgrid)</span>
<span id="cb59-11"><a href="non-linear-models.html#cb59-11" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">matrix</span>(f, <span class="at">nrow =</span> <span class="fu">length</span>(xx1), <span class="at">byrow =</span> T)</span>
<span id="cb59-12"><a href="non-linear-models.html#cb59-12" tabindex="-1"></a></span>
<span id="cb59-13"><a href="non-linear-models.html#cb59-13" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb59-14"><a href="non-linear-models.html#cb59-14" tabindex="-1"></a>fig <span class="ot">&lt;-</span> <span class="fu">plot_ly</span>(<span class="at">x =</span> <span class="sc">~</span>xx1, <span class="at">y =</span> <span class="sc">~</span>xx2, <span class="at">z =</span> <span class="sc">~</span>z, <span class="at">type =</span> <span class="st">&#39;surface&#39;</span>, <span class="at">showscale =</span> F) <span class="sc">%&gt;%</span> </span>
<span id="cb59-15"><a href="non-linear-models.html#cb59-15" tabindex="-1"></a>  <span class="fu">add_markers</span>(<span class="at">x =</span> train_pros<span class="sc">$</span>age, <span class="at">y =</span> train_pros<span class="sc">$</span>lbph, <span class="at">z =</span> train_pros<span class="sc">$</span>lpsa, </span>
<span id="cb59-16"><a href="non-linear-models.html#cb59-16" tabindex="-1"></a>              <span class="at">inherit =</span> F, <span class="at">showlegend =</span> F, <span class="at">marker =</span> <span class="fu">list</span>(<span class="at">size =</span> <span class="dv">5</span>,</span>
<span id="cb59-17"><a href="non-linear-models.html#cb59-17" tabindex="-1"></a>                                                         <span class="at">color =</span> <span class="st">&#39;magenta&#39;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb59-18"><a href="non-linear-models.html#cb59-18" tabindex="-1"></a>  <span class="fu">layout</span>(<span class="at">scene =</span> <span class="fu">list</span>(</span>
<span id="cb59-19"><a href="non-linear-models.html#cb59-19" tabindex="-1"></a>    <span class="at">xaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">&#39;Age&#39;</span>),</span>
<span id="cb59-20"><a href="non-linear-models.html#cb59-20" tabindex="-1"></a>    <span class="at">yaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">&#39;LBPH&#39;</span>),</span>
<span id="cb59-21"><a href="non-linear-models.html#cb59-21" tabindex="-1"></a>    <span class="at">zaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">&#39;LPSA&#39;</span>)</span>
<span id="cb59-22"><a href="non-linear-models.html#cb59-22" tabindex="-1"></a>  ))</span>
<span id="cb59-23"><a href="non-linear-models.html#cb59-23" tabindex="-1"></a>fig</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:knn-reg-2d"></span>
<div class="plotly html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-f33d931c7e293be7c01b" style="width:672px;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-f33d931c7e293be7c01b">{"x":{"visdat":{"508457c44b02":["function () ","plotlyVisDat"]},"cur_data":"508457c44b02","attrs":{"508457c44b02":{"x":{},"y":{},"z":{},"showscale":false,"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"surface"},"508457c44b02.1":{"x":[50,58,74,58,62,50,58,65,63,63,67,66,70,66,41,70,59,59,63,65,67,65,65,71,63,73,64,68,56,60,62,66,61,79,68,64,66,49,70,61,73,72,68,72,69,72,60,77,69,68,72,78,69,66,57,77,60,64,58,62,65,76,68,61,68,44,68],"y":[-1.38629436,-1.38629436,-1.38629436,-1.38629436,-1.38629436,-1.38629436,1.53686722,-1.38629436,1.2669476,-1.38629436,-1.38629436,-1.38629436,1.24415459,-1.38629436,-1.38629436,1.65822808,-1.38629436,-0.7985077,0.43825493,-1.38629436,0.22314355,-1.38629436,1.96290773,1.2669476,-1.38629436,-0.5798185,-1.38629436,1.37371558,0.93609336,-1.38629436,1.71379793,1.74919985,0.61518564,1.87946505,-1.38629436,2.07317193,2.12226154,1.42310833,0.43825493,1.29472717,2.32630162,-1.38629436,1.78339122,2.30757263,-1.38629436,2.32630162,-1.38629436,1.74919985,-1.38629436,-0.05129329,2.12226154,2.32630162,-1.38629436,0.55961579,0.43825493,-0.52763274,1.69561561,-1.38629436,1.63899671,-1.38629436,-1.38629436,0.93609336,-1.38629436,1.34807315,-1.38629436,-1.38629436,1.55814462],"z":[-0.4307829,-0.1625189,-0.1625189,-0.1625189,0.3715636,0.7654678,0.8544153,1.2669476,1.2669476,1.2669476,1.3480731,1.446919,1.4701758,1.4929041,1.5581446,1.5993876,1.6389967,1.6956156,1.7137979,1.8000583,1.8484548,1.8946169,1.9242487,2.008214,2.0476928,2.1575593,2.1916535,2.2137539,2.2772673,2.2975726,2.3272777,2.5217206,2.5533438,2.5687881,2.6567569,2.677591,2.7180005,2.7942279,2.8063861,2.8124102,2.8419982,2.8535925,2.9204698,2.9626924,2.9626924,2.9729753,3.0130809,3.0373539,3.2752562,3.3375474,3.3928291,3.4355988,3.4578927,3.5160131,3.5307626,3.5652984,3.5876769,3.6309855,3.6800909,3.7123518,3.9843437,3.993603,4.029806,4.1295508,4.3851468,4.6844434,5.477509],"type":"scatter3d","mode":"markers","showlegend":false,"marker":{"size":5,"color":"magenta"},"inherit":false}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"Age"},"yaxis":{"title":"LBPH"},"zaxis":{"title":"LPSA"}},"hovermode":"closest","showlegend":false},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"colorbar":{"title":"z","ticklen":2},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":false,"x":[41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79],"y":[-1.38629436,-1.28859446578947,-1.19089457157895,-1.09319467736842,-0.995494783157895,-0.897794888947368,-0.800094994736842,-0.702395100526316,-0.604695206315789,-0.506995312105263,-0.409295417894737,-0.311595523684211,-0.213895629473684,-0.116195735263158,-0.0184958410526315,0.0792040531578948,0.176903947368421,0.274603841578947,0.372303735789474,0.47000363,0.567703524210526,0.665403418421052,0.763103312631579,0.860803206842105,0.958503101052631,1.05620299526316,1.15390288947368,1.25160278368421,1.34930267789474,1.44700257210526,1.54470246631579,1.64240236052632,1.74010225473684,1.83780214894737,1.93550204315789,2.03320193736842,2.13090183157895,2.22860172578947,2.32630162],"z":[[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.67304276666667,1.67304276666667,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.06857493333333,1.06857493333333,0.4379863,1.38670466666667,2.31655006666667,2.348642225,1.84963895,2.20353246666667,2.2604057375,2.236491625,1.89055181428571,2.55993431666667,3.6905699,3.2319471,3.2319471,3.13735845,1.61621096666667,1.61621096666667,1.61621096666667,1.85344626666667,2.46546083333333,2.46546083333333,3.5320851,3.0571468],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.67304276666667,1.67304276666667,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.06857493333333,1.06857493333333,0.4379863,1.38670466666667,2.31655006666667,2.348642225,1.84963895,2.20353246666667,2.2604057375,2.236491625,1.89055181428571,2.55993431666667,3.6905699,3.2319471,3.2319471,3.07116398,1.61621096666667,1.61621096666667,1.61621096666667,1.85344626666667,2.46546083333333,2.46546083333333,3.5320851,3.0571468],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.67304276666667,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.06857493333333,1.06857493333333,0.4379863,1.38670466666667,2.31655006666667,2.348642225,1.84963895,2.20353246666667,2.2604057375,2.236491625,1.89055181428571,2.55993431666667,3.6905699,3.2319471,3.2319471,3.07116398,1.61621096666667,1.61621096666667,1.61621096666667,1.85344626666667,2.46546083333333,3.5320851,3.5320851,3.0571468],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.67304276666667,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.06857493333333,1.06857493333333,0.4379863,1.38670466666667,2.31655006666667,2.348642225,1.84963895,2.20353246666667,2.2604057375,2.236491625,1.89055181428571,2.55993431666667,3.6905699,3.2319471,3.2319471,3.07116398,1.61621096666667,1.61621096666667,1.61621096666667,1.85344626666667,2.46546083333333,3.5320851,3.5320851,3.0571468],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.67304276666667,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.370748025,1.06857493333333,0.456859266666667,1.38670466666667,2.33542303333333,2.348642225,1.84963895,2.20353246666667,2.2604057375,2.236491625,1.89055181428571,2.55993431666667,3.6905699,3.2319471,3.2319471,3.07116398,1.61621096666667,1.61621096666667,1.61621096666667,1.85344626666667,2.46546083333333,3.5320851,3.5320851,3.0571468],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.67304276666667,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.370748025,1.06857493333333,0.456859266666667,1.38670466666667,2.33542303333333,2.348642225,1.84963895,2.20353246666667,2.2604057375,2.236491625,1.89055181428571,2.55993431666667,3.6905699,3.2319471,3.2319471,2.60584596666667,1.61621096666667,1.61621096666667,1.61621096666667,1.85344626666667,2.46546083333333,3.5320851,3.5320851,3.0571468],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.370748025,1.06857493333333,0.456859266666667,1.38670466666667,2.33542303333333,2.348642225,1.84963895,2.20353246666667,2.2604057375,2.236491625,1.89055181428571,2.45829438571429,3.6905699,3.2319471,3.2319471,2.60584596666667,1.61621096666667,1.61621096666667,1.61621096666667,1.99621446666667,2.46546083333333,3.5320851,3.5320851,3.0571468],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.370748025,1.06857493333333,0.456859266666667,1.38670466666667,2.33542303333333,2.348642225,1.84963895,1.6761461,2.2604057375,2.236491625,1.89055181428571,2.1780251,3.602314275,3.2319471,3.12555685,2.5560642,1.61621096666667,1.61621096666667,1.61621096666667,1.99621446666667,2.46546083333333,3.5320851,3.5320851,3.0571468],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.370748025,1.06857493333333,0.456859266666667,1.38670466666667,2.33542303333333,2.38958254,1.84963895,1.6761461,2.2604057375,2.236491625,2.1519454,2.1780251,3.602314275,3.2319471,3.12555685,2.5560642,2.3397886,1.61621096666667,1.61621096666667,1.99621446666667,2.46546083333333,3.5320851,3.5320851,3.0571468],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.370748025,1.06857493333333,0.456859266666667,1.38670466666667,2.33542303333333,2.38958254,1.84963895,1.6761461,2.2604057375,2.236491625,2.1519454,2.1780251,3.602314275,3.2319471,3.12555685,2.5560642,2.3397886,1.61621096666667,1.61621096666667,2.46546083333333,2.46546083333333,3.5320851,3.5320851,3.1898951],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.370748025,1.06857493333333,0.456859266666667,1.38670466666667,2.33542303333333,2.38958254,1.9325711,1.6761461,2.51214563333333,2.236491625,2.1519454,2.1780251,3.602314275,3.2319471,3.12555685,2.5560642,2.3397886,1.61621096666667,1.61621096666667,2.46546083333333,2.46546083333333,3.5320851,3.5320851,3.1898951],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.370748025,1.06857493333333,0.456859266666667,1.38670466666667,2.33542303333333,2.38958254,1.9325711,1.6761461,2.51214563333333,2.236491625,2.1519454,2.1780251,3.602314275,3.258347175,3.12555685,2.5560642,2.3397886,1.61621096666667,1.61621096666667,2.46546083333333,2.46546083333333,3.5320851,3.5320851,3.1898951],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.370748025,1.370748025,0.456859266666667,1.38670466666667,2.33542303333333,2.46005381666667,1.9325711,1.6761461,2.51214563333333,2.236491625,2.07607275,2.1780251,3.25154238,3.258347175,2.79448064,2.5560642,2.3397886,1.61621096666667,1.99621446666667,2.46546083333333,3.5320851,3.5320851,3.5320851,3.1898951],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.370748025,1.370748025,1.2253351,1.38670466666667,2.389903225,3.1651016,2.087764275,1.6761461,2.51214563333333,2.49239592,2.07607275,2.90067176666667,3.25154238,3.16795496,2.79448064,2.5560642,2.3397886,1.61621096666667,1.99621446666667,2.46546083333333,3.5320851,3.5320851,3.0571468,3.1898951],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,0.969612833333333,1.370748025,1.370748025,1.370748025,1.2253351,1.38670466666667,2.389903225,3.1651016,2.087764275,1.573846475,2.51214563333333,2.49239592,2.07607275,2.90067176666667,3.25154238,3.16795496,2.0949253,2.0949253,2.3397886,1.61621096666667,1.99621446666667,2.46546083333333,3.5320851,3.5320851,3.0571468,3.1898951],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.02693116666667,1.39634253333333,2.389903225,3.1651016,2.087764275,1.573846475,2.51214563333333,2.49239592,2.07607275,2.90067176666667,2.46658536666667,3.16795496,2.0949253,2.0949253,2.3397886,1.61621096666667,1.99621446666667,2.46546083333333,3.5320851,3.5320851,3.0571468,3.1898951],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.02693116666667,1.39634253333333,2.35378986666667,3.1651016,1.84469643333333,1.573846475,2.200846125,2.49239592,2.07607275,2.90067176666667,2.46658536666667,2.53803643333333,2.0949253,2.0949253,2.3397886,1.61621096666667,1.99621446666667,2.46546083333333,3.5320851,3.5320851,3.0571468,3.1898951],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,1.39634253333333,2.98447696666667,3.1651016,1.84469643333333,1.573846475,2.200846125,2.49239592,2.6287295,2.90067176666667,2.46658536666667,2.53803643333333,1.95864983333333,2.0949253,2.3397886,1.61621096666667,1.99621446666667,2.46546083333333,3.5320851,3.5320851,3.0571468,3.1898951],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.07670726666667,2.98447696666667,3.1651016,2.1981398,1.76934106666667,1.88611216666667,2.65399413333333,2.6287295,2.90067176666667,2.46658536666667,2.53803643333333,1.95864983333333,2.0949253,2.51953413333333,2.7974622,1.99621446666667,2.46546083333333,3.5320851,3.5320851,3.0571468,3.1898951],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.07670726666667,2.98447696666667,3.1651016,2.1981398,1.76934106666667,1.88611216666667,2.65399413333333,2.6287295,2.90067176666667,2.46658536666667,2.53803643333333,1.95864983333333,2.0949253,2.51953413333333,2.7974622,1.99621446666667,2.46546083333333,3.5320851,3.5320851,3.0571468,3.1898951],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.07670726666667,2.98447696666667,3.1651016,2.1981398,1.76934106666667,1.88611216666667,2.65399413333333,2.6287295,2.90067176666667,3.6762701,2.53803643333333,1.95864983333333,2.0949253,2.51953413333333,2.7974622,1.6123462,2.46546083333333,3.5320851,3.5320851,3.0571468,3.1898951],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.70739436666667,2.98447696666667,3.1651016,2.1981398,1.76934106666667,1.88611216666667,2.65399413333333,2.6287295,2.52607393333333,3.6762701,2.1634386,1.95864983333333,2.0949253,2.51953413333333,2.7974622,2.99772016666667,2.28947933333333,3.5320851,3.5320851,3.0571468,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.70739436666667,2.98447696666667,3.1651016,2.1981398,1.76934106666667,1.88611216666667,2.65399413333333,2.6287295,2.52607393333333,3.6762701,2.1634386,1.95864983333333,2.0949253,2.78791183333333,2.7974622,2.99772016666667,2.28947933333333,3.5320851,3.5320851,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.70739436666667,2.98447696666667,3.1651016,2.0491897,1.76934106666667,1.88611216666667,2.65399413333333,2.6287295,2.52607393333333,3.6762701,2.1634386,1.95864983333333,2.0949253,2.78791183333333,2.7974622,2.99772016666667,3.5320851,3.5320851,3.5320851,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.70739436666667,2.98447696666667,3.1651016,2.13554516666667,1.76934106666667,1.88611216666667,2.65399413333333,2.91857806666667,2.52607393333333,3.53724423333333,2.1634386,1.95864983333333,2.0949253,2.78791183333333,2.7974622,2.99772016666667,3.29098503333333,3.5320851,3.5320851,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.70739436666667,3.5098793,3.1651016,2.13554516666667,1.76934106666667,1.88611216666667,2.65399413333333,2.91857806666667,2.52607393333333,3.53724423333333,3.0538129,1.95864983333333,1.69259246666667,2.78791183333333,3.0658399,2.99772016666667,3.29098503333333,3.5320851,3.5320851,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.70739436666667,3.5098793,3.1651016,2.13554516666667,1.76934106666667,1.88611216666667,2.65399413333333,2.91857806666667,3.1799059,3.53724423333333,3.0538129,1.95864983333333,1.69259246666667,2.78791183333333,3.0658399,2.99772016666667,3.29098503333333,3.5320851,3.4888519,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,0.870650733333333,2.22081506666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.70739436666667,3.5098793,3.1651016,2.13554516666667,1.76934106666667,1.95626243333333,2.65399413333333,2.91857806666667,3.1799059,3.53724423333333,3.0538129,1.95864983333333,1.69259246666667,2.78791183333333,3.0658399,2.99772016666667,3.29098503333333,3.5320851,3.4888519,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.351545025,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.68842293333333,2.70739436666667,3.5098793,3.1651016,3.08974623333333,1.76934106666667,1.95626243333333,2.3745201,2.91857806666667,3.40432783333333,3.53724423333333,3.0538129,1.95864983333333,1.69259246666667,3.10949893333333,3.0658399,3.40947676666667,3.29098503333333,3.5320851,3.4888519,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,2.86741926666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.68842293333333,2.70739436666667,3.5098793,3.1651016,3.08974623333333,1.76934106666667,1.95626243333333,2.3745201,2.91857806666667,3.40432783333333,3.53724423333333,3.0538129,1.95864983333333,1.69259246666667,3.10949893333333,3.0658399,3.40947676666667,3.29098503333333,3.4888519,3.4888519,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,2.86741926666667,2.22081506666667,2.22081506666667,2.22081506666667,2.68842293333333,2.68842293333333,2.70739436666667,3.5098793,3.1651016,3.08974623333333,1.76934106666667,1.95626243333333,2.3745201,2.91857806666667,3.40432783333333,3.53724423333333,3.0968835,1.69259246666667,1.69259246666667,3.10949893333333,3.0658399,3.40947676666667,3.29098503333333,3.4888519,3.4888519,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,2.86741926666667,3.16270693333333,3.16270693333333,3.16270693333333,2.68842293333333,2.68842293333333,2.70739436666667,3.5098793,3.5098793,3.08974623333333,2.09060543333333,1.95626243333333,2.3745201,2.38798993333333,3.6398998,3.53724423333333,3.33245546666667,1.69259246666667,1.69259246666667,3.10949893333333,3.0658399,3.0658399,3.29098503333333,3.4888519,3.4888519,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,2.86741926666667,3.16270693333333,3.16270693333333,3.16270693333333,2.27059116666667,2.68842293333333,2.70739436666667,3.5098793,3.08974623333333,3.08974623333333,2.09060543333333,1.95626243333333,2.3745201,2.38798993333333,3.6398998,3.53724423333333,3.33245546666667,1.69259246666667,2.3334769,3.10949893333333,3.0658399,3.0658399,3.29098503333333,3.4888519,3.4888519,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,2.86741926666667,3.16270693333333,3.16270693333333,3.16270693333333,2.27059116666667,2.68842293333333,2.70739436666667,3.5098793,3.08974623333333,3.08974623333333,2.09060543333333,1.95626243333333,2.3745201,2.38798993333333,3.6398998,3.53724423333333,3.33245546666667,1.69259246666667,2.3334769,3.10949893333333,3.0658399,3.0658399,3.29098503333333,3.4888519,3.4888519,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,2.86741926666667,3.16270693333333,3.16270693333333,3.16270693333333,2.27059116666667,2.68842293333333,2.70739436666667,3.5098793,3.08974623333333,3.08974623333333,2.09060543333333,1.95626243333333,2.3745201,2.38798993333333,2.72006363333333,3.53724423333333,3.33245546666667,1.69259246666667,2.3334769,3.10949893333333,3.0658399,3.0658399,3.29098503333333,3.4888519,3.4888519,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,2.86741926666667,3.16270693333333,3.16270693333333,3.16270693333333,2.27059116666667,2.68842293333333,2.70739436666667,3.5098793,3.08974623333333,3.08974623333333,2.09060543333333,1.95626243333333,2.43994673333333,2.38798993333333,2.72006363333333,3.53724423333333,3.33245546666667,1.69259246666667,2.78791183333333,3.10949893333333,3.0658399,3.0658399,3.29098503333333,3.4888519,3.4888519,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,2.86741926666667,3.16270693333333,3.16270693333333,3.16270693333333,2.27059116666667,2.68842293333333,2.70739436666667,3.5098793,3.08974623333333,3.08974623333333,2.09060543333333,1.95626243333333,2.43994673333333,2.38798993333333,2.72006363333333,3.53724423333333,3.33245546666667,1.69259246666667,2.78791183333333,3.10949893333333,3.0658399,3.0658399,3.29098503333333,3.4888519,3.4888519,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,2.86741926666667,3.16270693333333,3.16270693333333,3.16270693333333,2.27059116666667,2.68842293333333,2.70739436666667,3.5098793,3.08974623333333,3.08974623333333,2.09060543333333,1.95626243333333,2.43994673333333,2.38798993333333,2.72006363333333,3.53724423333333,3.33245546666667,1.69259246666667,2.64796056666667,3.10949893333333,2.92588863333333,2.92588863333333,3.29098503333333,3.4888519,3.4888519,3.0139136,3.0139136],[3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,3.01227196666667,1.95333905,1.95333905,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,1.04297093333333,2.86741926666667,3.16270693333333,3.16270693333333,3.16270693333333,2.27059116666667,2.70739436666667,2.70739436666667,3.5098793,3.08974623333333,3.08974623333333,2.09060543333333,1.95626243333333,2.43994673333333,2.38798993333333,2.72006363333333,3.53724423333333,3.33245546666667,1.69259246666667,3.10949893333333,3.10949893333333,2.92588863333333,2.92588863333333,3.29098503333333,3.4888519,3.4888519,3.0139136,3.0139136]],"type":"surface","frame":null},{"x":[50,58,74,58,62,50,58,65,63,63,67,66,70,66,41,70,59,59,63,65,67,65,65,71,63,73,64,68,56,60,62,66,61,79,68,64,66,49,70,61,73,72,68,72,69,72,60,77,69,68,72,78,69,66,57,77,60,64,58,62,65,76,68,61,68,44,68],"y":[-1.38629436,-1.38629436,-1.38629436,-1.38629436,-1.38629436,-1.38629436,1.53686722,-1.38629436,1.2669476,-1.38629436,-1.38629436,-1.38629436,1.24415459,-1.38629436,-1.38629436,1.65822808,-1.38629436,-0.7985077,0.43825493,-1.38629436,0.22314355,-1.38629436,1.96290773,1.2669476,-1.38629436,-0.5798185,-1.38629436,1.37371558,0.93609336,-1.38629436,1.71379793,1.74919985,0.61518564,1.87946505,-1.38629436,2.07317193,2.12226154,1.42310833,0.43825493,1.29472717,2.32630162,-1.38629436,1.78339122,2.30757263,-1.38629436,2.32630162,-1.38629436,1.74919985,-1.38629436,-0.05129329,2.12226154,2.32630162,-1.38629436,0.55961579,0.43825493,-0.52763274,1.69561561,-1.38629436,1.63899671,-1.38629436,-1.38629436,0.93609336,-1.38629436,1.34807315,-1.38629436,-1.38629436,1.55814462],"z":[-0.4307829,-0.1625189,-0.1625189,-0.1625189,0.3715636,0.7654678,0.8544153,1.2669476,1.2669476,1.2669476,1.3480731,1.446919,1.4701758,1.4929041,1.5581446,1.5993876,1.6389967,1.6956156,1.7137979,1.8000583,1.8484548,1.8946169,1.9242487,2.008214,2.0476928,2.1575593,2.1916535,2.2137539,2.2772673,2.2975726,2.3272777,2.5217206,2.5533438,2.5687881,2.6567569,2.677591,2.7180005,2.7942279,2.8063861,2.8124102,2.8419982,2.8535925,2.9204698,2.9626924,2.9626924,2.9729753,3.0130809,3.0373539,3.2752562,3.3375474,3.3928291,3.4355988,3.4578927,3.5160131,3.5307626,3.5652984,3.5876769,3.6309855,3.6800909,3.7123518,3.9843437,3.993603,4.029806,4.1295508,4.3851468,4.6844434,5.477509],"type":"scatter3d","mode":"markers","showlegend":false,"marker":{"color":"magenta","size":5,"line":{"color":"rgba(255,127,14,1)"}},"error_y":{"color":"rgba(255,127,14,1)"},"error_x":{"color":"rgba(255,127,14,1)"},"line":{"color":"rgba(255,127,14,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p class="caption">
Figure 5.7: KNN regression with <span class="math inline">\(K\)</span> = 3 applied to the prostate cancer dataset, using age and lbph
</p>
</div>
<p>Now, <span class="math inline">\(K = 3\)</span> was chosen arbitrarily here, hence the question again arises of which value of <span class="math inline">\(K\)</span> to use, i.e. what our model complexity should be. Once again we will make use of cross-validation to fit and validate models of varying complexity. We will now introduce the <code>caret</code> package as a tool for performing this <strong>hyperparameter tuning</strong>.</p>
<p>One of the drawbacks of KNN is that there is no sensible way of determining how much a specific variable contributes towards explaining the variance in the target variable, which makes feature selection a difficult, often trial-and-error process. Since we have relatively few observations in this dataset, we will only use 3 predictors – the last 3 predictors that remain in the lasso model – namely <code>lcavol</code>, <code>lweight</code>, and <code>svi</code>.</p>
<p>Also, since the dataset is so small, we will repeat the CV procedure 10 times and average over the results.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="non-linear-models.html#cb60-1" tabindex="-1"></a><span class="co"># See names(getModelInfo()) for a list of algorithms in caret</span></span>
<span id="cb60-2"><a href="non-linear-models.html#cb60-2" tabindex="-1"></a></span>
<span id="cb60-3"><a href="non-linear-models.html#cb60-3" tabindex="-1"></a><span class="co"># This is where one would specify combinations of hyperparameters</span></span>
<span id="cb60-4"><a href="non-linear-models.html#cb60-4" tabindex="-1"></a>knn_grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">k =</span> <span class="dv">3</span><span class="sc">:</span><span class="dv">15</span>) </span>
<span id="cb60-5"><a href="non-linear-models.html#cb60-5" tabindex="-1"></a><span class="co"># knn only only has one: k. See getModelInfo()$knn$parameters</span></span>
<span id="cb60-6"><a href="non-linear-models.html#cb60-6" tabindex="-1"></a></span>
<span id="cb60-7"><a href="non-linear-models.html#cb60-7" tabindex="-1"></a><span class="co"># Specify the CV procedure</span></span>
<span id="cb60-8"><a href="non-linear-models.html#cb60-8" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span>  <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&#39;repeatedcv&#39;</span>, <span class="at">number =</span> <span class="dv">10</span>, <span class="at">repeats =</span> <span class="dv">10</span>)</span>
<span id="cb60-9"><a href="non-linear-models.html#cb60-9" tabindex="-1"></a></span>
<span id="cb60-10"><a href="non-linear-models.html#cb60-10" tabindex="-1"></a><span class="co"># Use train() to fit all the models</span></span>
<span id="cb60-11"><a href="non-linear-models.html#cb60-11" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4026</span>)</span>
<span id="cb60-12"><a href="non-linear-models.html#cb60-12" tabindex="-1"></a>knn_cv <span class="ot">&lt;-</span> <span class="fu">train</span>(lpsa <span class="sc">~</span> lcavol <span class="sc">+</span> lweight <span class="sc">+</span> svi,</span>
<span id="cb60-13"><a href="non-linear-models.html#cb60-13" tabindex="-1"></a>                <span class="at">data =</span> train_pros,</span>
<span id="cb60-14"><a href="non-linear-models.html#cb60-14" tabindex="-1"></a>                <span class="at">method =</span> <span class="st">&#39;knn&#39;</span>, </span>
<span id="cb60-15"><a href="non-linear-models.html#cb60-15" tabindex="-1"></a>                <span class="at">trControl =</span> ctrl,</span>
<span id="cb60-16"><a href="non-linear-models.html#cb60-16" tabindex="-1"></a>                <span class="at">tuneGrid =</span> knn_grid)</span>
<span id="cb60-17"><a href="non-linear-models.html#cb60-17" tabindex="-1"></a></span>
<span id="cb60-18"><a href="non-linear-models.html#cb60-18" tabindex="-1"></a><span class="co"># Plot results</span></span>
<span id="cb60-19"><a href="non-linear-models.html#cb60-19" tabindex="-1"></a><span class="fu">plot</span>(knn_cv) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:knn-reg"></span>
<img src="figs/knn-reg-1.png" alt="Repeated CV results for KNN as applied to the prostate cancer dataset." width="576" />
<p class="caption">
Figure 5.8: Repeated CV results for KNN as applied to the prostate cancer dataset.
</p>
</div>
<p>As can be seen in <a href="non-linear-models.html#fig:knn-reg">5.8</a>, the best KNN model according to the CV procedure (lowest RMSE) is one with <span class="math inline">\(K = 6\)</span>. Remember that for this model, lower <span class="math inline">\(K\)</span> increases flexibility, therefore the model starts overfitting for <span class="math inline">\(K\)</span> smaller than 6. Now we use this model to predict on the test set.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="non-linear-models.html#cb61-1" tabindex="-1"></a>test_y <span class="ot">&lt;-</span> test_pros[, <span class="dv">9</span>]</span>
<span id="cb61-2"><a href="non-linear-models.html#cb61-2" tabindex="-1"></a></span>
<span id="cb61-3"><a href="non-linear-models.html#cb61-3" tabindex="-1"></a>knn_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_cv, test_pros)</span>
<span id="cb61-4"><a href="non-linear-models.html#cb61-4" tabindex="-1"></a>(knn_mse <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">mean</span>((test_y <span class="sc">-</span> knn_pred)<span class="sc">^</span><span class="dv">2</span>), <span class="dv">3</span>))</span></code></pre></div>
<pre><code>## [1] 0.39</code></pre>
<p>The testing MSE of 0.39 is actually noticeably better than our best regularised linear model, which yielded an MSE of 0.45. Testing other combinations of features, which could possibly improve the results further, is left as a homework exercise.</p>
<p>Finally, we will apply KNN in a classification setting.</p>
</div>
<div id="classification-1" class="section level3 hasAnchor" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Classification<a href="non-linear-models.html#classification-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The training setup in the classification setting is exactly the same as for regression. Let the target <span class="math inline">\(Y \in \{1, 2, \ldots, J\}\)</span> and again denote the <span class="math inline">\(K\)</span> training observations closest to <span class="math inline">\(\boldsymbol{x}_0\)</span> as <span class="math inline">\(\mathcal{N}_0\)</span>. The KNN classifier then simply estimates the conditional probability for class <span class="math inline">\(j\)</span> as the proportion of points in <span class="math inline">\(\mathcal{N}_0\)</span> whose response values equal <span class="math inline">\(j\)</span>:</p>
<span class="math display" id="eq:knn-class">\[\begin{equation}
\Pr(Y=j|\boldsymbol{X} = \boldsymbol{x}_0) = \frac{1}{K}\sum_{\boldsymbol{x}_i \in \mathcal{N}_0} I(y_i = j).
\tag{5.4}
\end{equation}\]</span>
<p>To illustrate this, we will again return to the heart failure dataset.</p>
</div>
<div id="example-4-heart-failure-continued-1" class="section level3 hasAnchor" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Example 4 – Heart failure (continued)<a href="non-linear-models.html#example-4-heart-failure-continued-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To illustrate the decision boundary resulting from the KNN classifier, consider again the predictors <code>age</code> and <code>ejection_fraction</code>. We will use the <code>class</code> package’s <code>knn()</code> function, although note that many other packages provide the same functionality.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="non-linear-models.html#cb63-1" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb63-2"><a href="non-linear-models.html#cb63-2" tabindex="-1"></a></span>
<span id="cb63-3"><a href="non-linear-models.html#cb63-3" tabindex="-1"></a>xx1 <span class="ot">&lt;-</span> <span class="fu">min</span>(heart<span class="sc">$</span>age)<span class="sc">:</span><span class="fu">max</span>(heart<span class="sc">$</span>age)</span>
<span id="cb63-4"><a href="non-linear-models.html#cb63-4" tabindex="-1"></a>xx2 <span class="ot">&lt;-</span> <span class="fu">min</span>(heart<span class="sc">$</span>ejection_fraction)<span class="sc">:</span><span class="fu">max</span>(heart<span class="sc">$</span>ejection_fraction)</span>
<span id="cb63-5"><a href="non-linear-models.html#cb63-5" tabindex="-1"></a></span>
<span id="cb63-6"><a href="non-linear-models.html#cb63-6" tabindex="-1"></a>fgrid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">age =</span> xx1, <span class="at">ejection_fraction =</span> xx2)</span>
<span id="cb63-7"><a href="non-linear-models.html#cb63-7" tabindex="-1"></a></span>
<span id="cb63-8"><a href="non-linear-models.html#cb63-8" tabindex="-1"></a>tr <span class="ot">&lt;-</span> <span class="fu">select</span>(heart, age, ejection_fraction)</span>
<span id="cb63-9"><a href="non-linear-models.html#cb63-9" tabindex="-1"></a></span>
<span id="cb63-10"><a href="non-linear-models.html#cb63-10" tabindex="-1"></a><span class="co"># Fit KNN with k = 3</span></span>
<span id="cb63-11"><a href="non-linear-models.html#cb63-11" tabindex="-1"></a>knn3_class <span class="ot">&lt;-</span> <span class="fu">knn</span>(tr, fgrid, heart<span class="sc">$</span>DEATH_EVENT, <span class="at">k =</span> <span class="dv">3</span>)</span>
<span id="cb63-12"><a href="non-linear-models.html#cb63-12" tabindex="-1"></a>knn10_class <span class="ot">&lt;-</span> <span class="fu">knn</span>(tr, fgrid, heart<span class="sc">$</span>DEATH_EVENT, <span class="at">k =</span> <span class="dv">10</span>)</span>
<span id="cb63-13"><a href="non-linear-models.html#cb63-13" tabindex="-1"></a>fgrid<span class="sc">$</span>f3 <span class="ot">&lt;-</span> knn3_class</span>
<span id="cb63-14"><a href="non-linear-models.html#cb63-14" tabindex="-1"></a>fgrid<span class="sc">$</span>f10 <span class="ot">&lt;-</span> knn10_class</span>
<span id="cb63-15"><a href="non-linear-models.html#cb63-15" tabindex="-1"></a></span>
<span id="cb63-16"><a href="non-linear-models.html#cb63-16" tabindex="-1"></a><span class="co">#Animation taking too long...Something for future</span></span>
<span id="cb63-17"><a href="non-linear-models.html#cb63-17" tabindex="-1"></a><span class="co"># fitmat_3 &lt;- matrix(knn3_class, nrow = length(xx1), byrow = T)</span></span>
<span id="cb63-18"><a href="non-linear-models.html#cb63-18" tabindex="-1"></a><span class="co"># fitmat_10&lt;- matrix(knn10_class, nrow = length(xx1), byrow = T)</span></span>
<span id="cb63-19"><a href="non-linear-models.html#cb63-19" tabindex="-1"></a><span class="co"># for(i in 1:length(xx1)){</span></span>
<span id="cb63-20"><a href="non-linear-models.html#cb63-20" tabindex="-1"></a><span class="co">#   for(j in 1:length(xx2)){</span></span>
<span id="cb63-21"><a href="non-linear-models.html#cb63-21" tabindex="-1"></a><span class="co">#     # Plot age vs ejection fraction</span></span>
<span id="cb63-22"><a href="non-linear-models.html#cb63-22" tabindex="-1"></a><span class="co">#     plot(heart$age, heart$ejection_fraction,</span></span>
<span id="cb63-23"><a href="non-linear-models.html#cb63-23" tabindex="-1"></a><span class="co">#          col = ifelse(heart$DEATH_EVENT == &#39;1&#39;, &#39;darkorange&#39;, &#39;lightblue&#39;),</span></span>
<span id="cb63-24"><a href="non-linear-models.html#cb63-24" tabindex="-1"></a><span class="co">#          pch = ifelse(heart$DEATH_EVENT == &#39;1&#39;, 3, 1),</span></span>
<span id="cb63-25"><a href="non-linear-models.html#cb63-25" tabindex="-1"></a><span class="co">#          xlab = &#39;Age&#39;, ylab = &#39;Ejection fraction&#39;, main = &#39;KNN classification with K = 3&#39;)</span></span>
<span id="cb63-26"><a href="non-linear-models.html#cb63-26" tabindex="-1"></a><span class="co">#     </span></span>
<span id="cb63-27"><a href="non-linear-models.html#cb63-27" tabindex="-1"></a><span class="co">#     points(xx1[i], xx2[j], pch = 15, </span></span>
<span id="cb63-28"><a href="non-linear-models.html#cb63-28" tabindex="-1"></a><span class="co">#            col = ifelse(fitmat_3[i,j] == 1,</span></span>
<span id="cb63-29"><a href="non-linear-models.html#cb63-29" tabindex="-1"></a><span class="co">#                         rgb(255, 140, 0, maxColorValue = 255, alpha = 255*0.4),</span></span>
<span id="cb63-30"><a href="non-linear-models.html#cb63-30" tabindex="-1"></a><span class="co">#                         rgb(173, 216, 230, maxColorValue = 255, alpha = 255*0.4)))</span></span>
<span id="cb63-31"><a href="non-linear-models.html#cb63-31" tabindex="-1"></a><span class="co">#     segments(xx1[i], min(xx2)/2, xx1[i], xx2[j], lty = 3)</span></span>
<span id="cb63-32"><a href="non-linear-models.html#cb63-32" tabindex="-1"></a><span class="co">#     segments(min(xx1)/2, xx2[j], xx1[i], xx2[j], lty = 3)</span></span>
<span id="cb63-33"><a href="non-linear-models.html#cb63-33" tabindex="-1"></a><span class="co">#   }</span></span>
<span id="cb63-34"><a href="non-linear-models.html#cb63-34" tabindex="-1"></a><span class="co"># }</span></span>
<span id="cb63-35"><a href="non-linear-models.html#cb63-35" tabindex="-1"></a></span>
<span id="cb63-36"><a href="non-linear-models.html#cb63-36" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb63-37"><a href="non-linear-models.html#cb63-37" tabindex="-1"></a></span>
<span id="cb63-38"><a href="non-linear-models.html#cb63-38" tabindex="-1"></a><span class="co"># K = 3</span></span>
<span id="cb63-39"><a href="non-linear-models.html#cb63-39" tabindex="-1"></a><span class="fu">plot</span>(heart<span class="sc">$</span>age, heart<span class="sc">$</span>ejection_fraction,</span>
<span id="cb63-40"><a href="non-linear-models.html#cb63-40" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">&#39;black&#39;</span>,</span>
<span id="cb63-41"><a href="non-linear-models.html#cb63-41" tabindex="-1"></a>     <span class="at">pch =</span> <span class="fu">ifelse</span>(heart<span class="sc">$</span>DEATH_EVENT <span class="sc">==</span> <span class="st">&#39;1&#39;</span>, <span class="dv">3</span>, <span class="dv">1</span>),</span>
<span id="cb63-42"><a href="non-linear-models.html#cb63-42" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Age&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;Ejection fraction&#39;</span>, <span class="at">main =</span> <span class="st">&#39;KNN classification with K = 3&#39;</span>)</span>
<span id="cb63-43"><a href="non-linear-models.html#cb63-43" tabindex="-1"></a></span>
<span id="cb63-44"><a href="non-linear-models.html#cb63-44" tabindex="-1"></a><span class="fu">points</span>(fgrid<span class="sc">$</span>age, fgrid<span class="sc">$</span>ejection_fraction, <span class="at">pch =</span> <span class="dv">15</span>, </span>
<span id="cb63-45"><a href="non-linear-models.html#cb63-45" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">ifelse</span>(fgrid<span class="sc">$</span>f3 <span class="sc">==</span> <span class="dv">1</span>, </span>
<span id="cb63-46"><a href="non-linear-models.html#cb63-46" tabindex="-1"></a>                    <span class="fu">rgb</span>(<span class="dv">255</span>, <span class="dv">140</span>, <span class="dv">0</span>, <span class="at">maxColorValue =</span> <span class="dv">255</span>, <span class="at">alpha =</span> <span class="dv">255</span><span class="sc">*</span><span class="fl">0.25</span>),</span>
<span id="cb63-47"><a href="non-linear-models.html#cb63-47" tabindex="-1"></a>                    <span class="fu">rgb</span>(<span class="dv">173</span>, <span class="dv">216</span>, <span class="dv">230</span>, <span class="at">maxColorValue =</span> <span class="dv">255</span>, <span class="at">alpha =</span> <span class="dv">255</span><span class="sc">*</span><span class="fl">0.25</span>)))</span>
<span id="cb63-48"><a href="non-linear-models.html#cb63-48" tabindex="-1"></a></span>
<span id="cb63-49"><a href="non-linear-models.html#cb63-49" tabindex="-1"></a><span class="co"># K = 10</span></span>
<span id="cb63-50"><a href="non-linear-models.html#cb63-50" tabindex="-1"></a><span class="fu">plot</span>(heart<span class="sc">$</span>age, heart<span class="sc">$</span>ejection_fraction,</span>
<span id="cb63-51"><a href="non-linear-models.html#cb63-51" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">&#39;black&#39;</span>,</span>
<span id="cb63-52"><a href="non-linear-models.html#cb63-52" tabindex="-1"></a>     <span class="at">pch =</span> <span class="fu">ifelse</span>(heart<span class="sc">$</span>DEATH_EVENT <span class="sc">==</span> <span class="st">&#39;1&#39;</span>, <span class="dv">3</span>, <span class="dv">1</span>),</span>
<span id="cb63-53"><a href="non-linear-models.html#cb63-53" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Age&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;Ejection fraction&#39;</span>, <span class="at">main =</span> <span class="st">&#39;KNN classification with K = 10&#39;</span>)</span>
<span id="cb63-54"><a href="non-linear-models.html#cb63-54" tabindex="-1"></a></span>
<span id="cb63-55"><a href="non-linear-models.html#cb63-55" tabindex="-1"></a><span class="fu">points</span>(fgrid<span class="sc">$</span>age, fgrid<span class="sc">$</span>ejection_fraction, <span class="at">pch =</span> <span class="dv">15</span>, </span>
<span id="cb63-56"><a href="non-linear-models.html#cb63-56" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">ifelse</span>(fgrid<span class="sc">$</span>f10 <span class="sc">==</span> <span class="dv">1</span>, </span>
<span id="cb63-57"><a href="non-linear-models.html#cb63-57" tabindex="-1"></a>                    <span class="fu">rgb</span>(<span class="dv">255</span>, <span class="dv">140</span>, <span class="dv">0</span>, <span class="at">maxColorValue =</span> <span class="dv">255</span>, <span class="at">alpha =</span> <span class="dv">255</span><span class="sc">*</span><span class="fl">0.25</span>),</span>
<span id="cb63-58"><a href="non-linear-models.html#cb63-58" tabindex="-1"></a>                    <span class="fu">rgb</span>(<span class="dv">173</span>, <span class="dv">216</span>, <span class="dv">230</span>, <span class="at">maxColorValue =</span> <span class="dv">255</span>, <span class="at">alpha =</span> <span class="dv">255</span><span class="sc">*</span><span class="fl">0.25</span>)))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:knn-class1"></span>
<img src="figs/knn-class1-1.png" alt="KNN regression with $K$ = 3 and $K$ = 10 on the heart failure dataset, using age and ejection fraction. Crosses are observed deaths, circles are survivals. The orange regions pertain to predicted death, the blue to predicted survival." width="864" />
<p class="caption">
Figure 5.9: KNN regression with <span class="math inline">\(K\)</span> = 3 and <span class="math inline">\(K\)</span> = 10 on the heart failure dataset, using age and ejection fraction. Crosses are observed deaths, circles are survivals. The orange regions pertain to predicted death, the blue to predicted survival.
</p>
</div>
<p>Figure <a href="non-linear-models.html#fig:knn-class1">5.9</a> shows highly flexible decision boundaries, which clearly fit local noise especially when <span class="math inline">\(K\)</span> is small. As before, we can use CV to determine the ideal complexity according to an appropriate model evaluation metric. This is left as a homework exercise.</p>
<p>As we have seen, there are several advantages and disadvantages to using KNN.</p>
<p>Advantages:</p>
<ol style="list-style-type: decimal">
<li>It is a very simple algorithm to understand and implement, for both regression and multiclass classification.</li>
<li>It does not make assumptions about the decision boundaries, allowing it to capture non-linear relationships between features.</li>
<li>It does not make assumptions about the distribution of the data, making it suitable for a wide range of problems.</li>
</ol>
<p>Disadvantages:</p>
<ol style="list-style-type: decimal">
<li>It requires a lot of memory and is computationally expensive for large and complex datasets.</li>
<li>It is not suitable for imbalanced data (classification), as it is biased towards the majority class.</li>
<li>In regression contexts it is sensitive to outliers, especially for smaller <span class="math inline">\(K\)</span>.</li>
<li>There are no neat ways of measuring variable importance or performing feature selection.</li>
<li>It performs particularly poorly on very noisy data.</li>
<li>It requires a lot of data for high-dimensional problems, suffering severely from the curse of dimensionality.</li>
</ol>
<p>In the final chapter, we will encounter another potentially powerful family of heuristics by exploring tree-based methods.</p>
</div>
</div>
<div id="homework-exercises-3" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Homework exercises<a href="non-linear-models.html#homework-exercises-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li>Split the heart failure dataset into the same training and testing sets as in chapter 4. Fit the polynomial regression from section 5.1.4 to the training set and compare the results with those from the linear models in chapter 4.</li>
<li>For the prostate cancer dataset, use different combinations of features in the KNN model, compare them according to CV RMSE, and evaluate the best combination on the test set. How does this compare with the model applied above?</li>
<li>Continuing with question 1, fit a KNN model (applying hyperparameter tuning) to the heart failure training set and compare the test set performance with the linear and polynomial regression models.</li>
</ol>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="9">
<li id="fn9"><p>Adding interaction terms with <code>origin</code> might be advisable.<a href="non-linear-models.html#fnref9" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classification-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="tree-based-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/SSBritz/STA4026S-Analytics-SecA/edit/main/05-Non-Linear.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/SSBritz/STA4026S-Analytics-SecA/blob/main/05-Non-Linear.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
